<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Python [1, -1][x == 0] 写法解释和用处</title>
    <url>/Python-1-1-x-0-%E5%86%99%E6%B3%95%E8%A7%A3%E9%87%8A%E5%92%8C%E7%94%A8%E5%A4%84/</url>
    <content><![CDATA[<h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p>这种写法通俗形式为 <strong>[条件为假, 条件为真][判断条件]</strong><br>在 Python 中，布尔型 True 转变为整数等于 1，False 转变为整数等于 0<br>所以条件为真时，返回第二个数，条件为假时，返回第一个数</p>
<h3 id="用处"><a href="#用处" class="headerlink" title="用处"></a>用处</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> x == <span class="number">0</span>:</span><br><span class="line">    a = -<span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    a = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>可以写成这样的形式</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">a = [<span class="number">1</span>, -<span class="number">1</span>][x == <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Dijkstra 最短路径算法 Python 实现</title>
    <url>/Dijkstra-%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95-Python-%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><p>使用 Dijkstra 算法求图中的任意顶点到其它顶点的最短路径（求出需要经过那些点以及最短距离）。</p>
<p>以下图为例：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_1.png" alt="image"></p>
<span id="more"></span>

<h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>可以使用二维数组来存储顶点之间边的关系</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_2.png" alt="image"></p>
<p>首先需要用一个一维数组 dis 来存储 初始顶点到其余各个顶点的初始路程，以求 1 顶点到其它各个顶点为例：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_3.png" alt="image"></p>
<p>将此时 dis 数组中的值称为最短路的“估计值”。</p>
<p>既然是求 1 号顶点到其余各个顶点的最短路程，那就先找一个离 1 号顶点最近的顶点。通过数组 dis 可知当前离 1 号顶点最近是 2 号顶点。当选择了 2 号顶点后，dis[2] 的值就已经从“估计值”变为了“确定值”，即 1 号顶点到 2 号顶点的最短路程就是当前 dis[2]值。为什么呢？因为目前离 1 号顶点最近的是 2 号顶点，并且这个图所有的边都是正数，那么肯定不可能通过第三个顶点中转，使得 1 号顶点到 2 号顶点的路程进一步缩短了。</p>
<p>既然选了 2 号顶点，接下来再来看 2 号顶点有哪些出边。有 2-&gt;3 和 2-&gt;4 这两条边。先讨论通过 2-&gt;3 这条边能否让 1 号顶点到 3 号顶点的路程变短。也就是说现在比较 dis[3] 和 dis[2] + G[2][3]的大小。其中 dis[3] 表示 1 号顶点到 3 号顶点的路程。dis[2] + G[2][3] 中 dis[2] 表示 1 号顶点到 2 号顶点的路程，G[2][3] 表示 2-&gt;3 这条边。所以 dis[2] + G[2][3] 就表示从 1 号顶点先到 2 号顶点，再通过 2-&gt;3 这条边，到达 3 号顶点的路程。</p>
<p>在本例中 dis[3] = 12，dis[2] + G[2][3] = 1 + 9 = 10，dis[3] &gt; dis[2] + G[2][3]，所以 dis[3] 要更新为 10。这个过程有个专业术语叫做“松弛”。即 1 号顶点到 3 号顶点的路程即 dis[3]，通过 2-&gt;3 这条边松弛成功。这是 Dijkstra 算法的主要思想：通过“边”来松弛初始顶点到其余各个顶点的路程。</p>
<p>同理通过 2-&gt;4（G[2][4]），可以将 dis[4]的值从 ∞ 松弛为 4（dis[4] 初始为 ∞，dis[2] + G[2][4] = 1 + 3 = 4，dis[4] &gt; dis[2] + G[2][4]，所以 dis[4] 要更新为 4）。</p>
<p>刚才对 2 号顶点所有的出边进行了松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_4.png" alt="image"></p>
<p>接下来，继续在剩下的 3、4、5 和 6 号顶点中，选出离 1 号顶点最近的顶点。通过上面更新过 dis 数组，当前离 1 号顶点最近是 4 号顶点。此时，dis[4] 的值已经从“估计值”变为了“确定值”。下面继续对 4 号顶点的所有出边（4-&gt;3，4-&gt;5 和 4-&gt;6）用刚才的方法进行松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_5.png" alt="image"></p>
<p>继续在剩下的 3、5 和 6 号顶点中，选出离 1 号顶点最近的顶点，这次选择 3 号顶点。此时，dis[3] 的值已经从“估计值”变为了“确定值”。对 3 号顶点的所有出边（3-&gt;5）进行松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_6.png" alt="image"></p>
<p>继续在剩下的 5 和 6 号顶点中，选出离 1 号顶点最近的顶点，这次选择 5 号顶点。此时，dis[5] 的值已经从“估计值”变为了“确定值”。对5号顶点的所有出边（5-&gt;4）进行松弛。松弛完毕之后 dis 数组为：</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_7.png" alt="image"></p>
<p>最后对 6 号顶点所有点出边进行松弛。因为这个例子中 6 号顶点没有出边，因此不用处理。到此，dis 数组中所有的值都已经从“估计值”变为了“确定值”。</p>
<p>最终 dis 数组如下，这便是 1 号顶点到其余各个顶点的最短路径。</p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/Dijkstra%20%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E7%AE%97%E6%B3%95%20Python%20%E5%AE%9E%E7%8E%B0_8.png" alt="image"></p>
<p>总结一下刚才的算法。算法的基本思想是：每次找到离源点（上面例子的源点就是 1 号顶点）最近的一个顶点，然后以该顶点为中心进行扩展，最终得到源点到其余所有点的最短路径。基本步骤如下：</p>
<ol>
<li>将所有的顶点分为两部分：已知最短路程的顶点集合 P 和未知最短路径的顶点集合 Q。最开始，已知最短路径的顶点集合 P 中只有源点一个顶点。这里用一个 visited[ i ]数组来记录哪些点在集合 P 中。例如对于某个顶点 i，如果 visited[ i ]为 1 则表示这个顶点在集合 P 中，如果 visited[ i ]为 0 则表示这个顶点在集合 Q 中；</li>
<li>设置源点 s 到自己的最短路径为 0 即 dis = 0。若存在源点有能直接到达的顶点 i，则把 dis[ i ]设为 G[s][ i ]。同时把所有其它（源点不能直接到达的）顶点的最短路径为设为 ∞；</li>
<li>在集合 Q 的所有顶点中选择一个离源点 s 最近的顶点  u（即 dis[u] 最小）加入到集合 P。并考察所有以点 u 为起点的边，对每一条边进行松弛操作。例如存在一条从 u 到 v 的边，那么可以通过将边 u-&gt;v 添加到尾部来拓展一条从 s 到 v 的路径，这条路径的长度是 dis[u] + G[u][v]。如果这个值比目前已知的 dis[v] 的值要小，我们可以用新值来替代当前 dis[v] 中的值；</li>
<li>重复第 3 步，如果集合 Q 为空，算法结束。最终 dis 数组中的值就是源点到所有顶点的最短路径</li>
</ol>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><ol>
<li><p>Dijkstra 算法不能应用于有负权重的图</p>
</li>
<li><p>Dijkstra 时间复杂度为 O(N<sup>2</sup>)</p>
</li>
</ol>
<h3 id="Python-实现"><a href="#Python-实现" class="headerlink" title="Python 实现"></a>Python 实现</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Dijkstra</span>(<span class="params">G, start</span>):</span></span><br><span class="line">    <span class="comment"># 输入是从 0 开始，所以起始点减 1</span></span><br><span class="line">    start = start - <span class="number">1</span></span><br><span class="line">    inf = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    node_num = <span class="built_in">len</span>(G)</span><br><span class="line">    <span class="comment"># visited 代表哪些顶点加入过</span></span><br><span class="line">    visited = [<span class="number">0</span>] * node_num</span><br><span class="line">    <span class="comment"># 初始顶点到其余顶点的距离</span></span><br><span class="line">    dis = &#123;node: G[start][node] <span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">range</span>(node_num)&#125;</span><br><span class="line">    <span class="comment"># parents 代表最终求出最短路径后，每个顶点的上一个顶点是谁，初始化为 -1，代表无上一个顶点</span></span><br><span class="line">    parents = &#123;node: -<span class="number">1</span> <span class="keyword">for</span> node <span class="keyword">in</span> <span class="built_in">range</span>(node_num)&#125;</span><br><span class="line">    <span class="comment"># 起始点加入进 visited 数组</span></span><br><span class="line">    visited[start] = <span class="number">1</span></span><br><span class="line">    <span class="comment"># 最开始的上一个顶点为初始顶点</span></span><br><span class="line">    last_point = start</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(node_num - <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 求出 dis 中未加入 visited 数组的最短距离和顶点</span></span><br><span class="line">        min_dis = inf</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(node_num):</span><br><span class="line">            <span class="keyword">if</span> visited[j] == <span class="number">0</span> <span class="keyword">and</span> dis[j] &lt; min_dis:</span><br><span class="line">                min_dis = dis[j]</span><br><span class="line">                <span class="comment"># 把该顶点做为下次遍历的上一个顶点</span></span><br><span class="line">                last_point = j</span><br><span class="line">        <span class="comment"># 最短顶点假加入 visited 数组</span></span><br><span class="line">        visited[last_point] = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 对首次循环做特殊处理，不然在首次循环时会没法求出该点的上一个顶点</span></span><br><span class="line">        <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">            parents[last_point] = start + <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(node_num):</span><br><span class="line">            <span class="keyword">if</span> G[last_point][k] &lt; inf <span class="keyword">and</span> dis[k] &gt; dis[last_point] + G[last_point][k]:</span><br><span class="line">                <span class="comment"># 如果有更短的路径，更新 dis 和 记录 parents</span></span><br><span class="line">                dis[k] = dis[last_point] + G[last_point][k]</span><br><span class="line">                parents[k] = last_point + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 因为从 0 开始，最后把顶点都加 1</span></span><br><span class="line">    <span class="keyword">return</span> &#123;key + <span class="number">1</span>: values <span class="keyword">for</span> key, values <span class="keyword">in</span> dis.items()&#125;, &#123;key + <span class="number">1</span>: values <span class="keyword">for</span> key, values <span class="keyword">in</span> parents.items()&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    inf = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">    G = [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">12</span>, inf, inf, inf],</span><br><span class="line">         [inf, <span class="number">0</span>, <span class="number">9</span>, <span class="number">3</span>, inf, inf],</span><br><span class="line">         [inf, inf, <span class="number">0</span>, inf, <span class="number">5</span>, inf],</span><br><span class="line">         [inf, inf, <span class="number">4</span>, <span class="number">0</span>, <span class="number">13</span>, <span class="number">15</span>],</span><br><span class="line">         [inf, inf, inf, inf, <span class="number">0</span>, <span class="number">4</span>],</span><br><span class="line">         [inf, inf, inf, inf, inf, <span class="number">0</span>]]</span><br><span class="line">    dis, parents = Dijkstra(G, <span class="number">1</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;dis: &quot;</span>, dis)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;parents: &quot;</span>, parents)</span><br></pre></td></tr></table></figure>

<p>输出为</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dis:  &#123;<span class="number">1</span>: <span class="number">0</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">8</span>, <span class="number">4</span>: <span class="number">4</span>, <span class="number">5</span>: <span class="number">13</span>, <span class="number">6</span>: <span class="number">17</span>&#125;</span><br><span class="line">parents:  &#123;<span class="number">1</span>: -<span class="number">1</span>, <span class="number">2</span>: <span class="number">1</span>, <span class="number">3</span>: <span class="number">4</span>, <span class="number">4</span>: <span class="number">2</span>, <span class="number">5</span>: <span class="number">3</span>, <span class="number">6</span>: <span class="number">5</span>&#125;</span><br></pre></td></tr></table></figure>

<p>如果求 1 号顶点到 6 号顶点的最短距离，dis[6] = 17，所以最短距离为 17。</p>
<p>再看 parents[6] = 5，说明 6 号顶点的上一个顶点为 5，parents[5] = 3，说明 5 号顶点的上一个顶点为 3，以此类推，最终 1 号顶点到 6 号顶点的路径为 1-&gt;2-&gt;4-&gt;3-&gt;5-&gt;6。</p>
<h3 id="优化思路"><a href="#优化思路" class="headerlink" title="优化思路"></a>优化思路</h3><ul>
<li>其中每次找到离 1 号顶点最近的顶点的时间复杂度是 O(N)，可以用“堆”来优化，使得这一部分的时间复杂度降低到 O(logN)；</li>
<li>另外对于边数 M 少于 N<sup>2</sup> 的稀疏图来说（把 M 远小于 N<sup>2</sup> 的图称为稀疏图，而 M 相对较大的图称为稠密图），可以用邻接表来代替邻接矩阵，使得整个时间复杂度优化到 O((M+N)logN)。注意，在最坏的情况下 M 就是 N<sup>2</sup>，这样的话 MlogN 要比 N<sup>2</sup> 还要大。但是大多数情况下并不会有那么多边，所以 (M+N)logN 要比 N<sup>2</sup> 小很多</li>
</ul>
]]></content>
      <categories>
        <category>DS&amp;A</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DS&amp;A</tag>
        <tag>Dijkstra</tag>
      </tags>
  </entry>
  <entry>
    <title>Python 日期格式，时间戳之间转换</title>
    <url>/Python-%E6%97%A5%E6%9C%9F%E6%A0%BC%E5%BC%8F%EF%BC%8C%E6%97%B6%E9%97%B4%E6%88%B3%E4%B9%8B%E9%97%B4%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<h3 id="获取当前时间戳"><a href="#获取当前时间戳" class="headerlink" title="获取当前时间戳"></a>获取当前时间戳</h3><ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">now &#x3D; time.time()</span><br><span class="line">print(&#39;now:&#39;, now, &#39;\n&#39;, type(now))</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">now: 1498926743.1411922 </span><br><span class="line"> &lt;class &#39;float&#39;&gt;</span><br></pre></td></tr></table></figure>

<h3 id="获取当前日期"><a href="#获取当前日期" class="headerlink" title="获取当前日期"></a>获取当前日期</h3><span id="more"></span>

<ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">datenow &#x3D; datetime.datetime.now()</span><br><span class="line">print(&#39;datenow:&#39;, datenow, &#39;\n&#39;, type(datenow))</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">datenow: 2017-07-02 00:34:35.272749 </span><br><span class="line"> &lt;class &#39;datetime.datetime&#39;&gt;</span><br></pre></td></tr></table></figure>

<h3 id="字符串格式更改"><a href="#字符串格式更改" class="headerlink" title="字符串格式更改"></a>字符串格式更改</h3><p>如a = “2017-07-02 00:34:35”，想改为 a = “2017/07/02 00:34:35”</p>
<ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a &#x3D; &quot;2013-10-10 23:40:00&quot;</span><br><span class="line">timeArray &#x3D; time.strptime(a, &quot;%Y-%m-%d %H:%M:%S&quot;)                # 先转换为时间数组</span><br><span class="line">otherStyleTime &#x3D; time.strftime(&quot;%Y&#x2F;%m&#x2F;%d %H:%M:%S&quot;, timeArray)   # 转换为其他格式</span><br><span class="line">print(&#39;otherStyleTime:&#39;, otherStyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">otherStyleTime: 2017&#x2F;07&#x2F;02 00:34:35</span><br></pre></td></tr></table></figure>

<h3 id="将字符串的时间转换为时间戳"><a href="#将字符串的时间转换为时间戳" class="headerlink" title="将字符串的时间转换为时间戳"></a>将字符串的时间转换为时间戳</h3><ul>
<li>方法：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a &#x3D; &quot;2017-07-02 00:34:35&quot; </span><br><span class="line">timeArray &#x3D; time.strptime(a, &quot;%Y-%m-%d %H:%M:%S&quot;)            # 将其转换为时间数组</span><br><span class="line">timeStamp &#x3D; int(time.mktime(timeArray))                      # 转换为时间戳</span><br><span class="line">print(&#39;timesStamp:&#39;, timeStamp)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timesStamp: 1498926875</span><br></pre></td></tr></table></figure>

<h3 id="时间戳转换为指定格式日期"><a href="#时间戳转换为指定格式日期" class="headerlink" title="时间戳转换为指定格式日期"></a>时间戳转换为指定格式日期</h3><ul>
<li>方法一：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">timeStamp &#x3D; 1498927046</span><br><span class="line">timeArray &#x3D; time.localtime(timeStamp)                              # 利用localtime()转换为时间数组</span><br><span class="line">otherStyleTime &#x3D; time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, timeArray)     # 格式化为需要的格式</span><br><span class="line">print(&#39;otherStyleTime:&#39;, otherStyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>方法二：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">timeStamp &#x3D; 1498927046</span><br><span class="line">dateArray &#x3D; datetime.datetime.fromtimestamp(timeStamp)</span><br><span class="line">otherStyleTime &#x3D; dateArray.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)</span><br><span class="line">print(&#39;otherStyleTime:&#39;, otherStyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">otherStyleTime: 2017-07-02 00:37:26</span><br></pre></td></tr></table></figure>

<h3 id="获取当前时间并转换为指定日期格式"><a href="#获取当前时间并转换为指定日期格式" class="headerlink" title="获取当前时间并转换为指定日期格式"></a>获取当前时间并转换为指定日期格式</h3><ul>
<li>方法一：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">now &#x3D; int(time.time())                                             # 获得当前时间时间戳</span><br><span class="line">timeArray &#x3D; time.localtime(now)</span><br><span class="line">StyleTime &#x3D; time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;, timeArray)</span><br><span class="line">print(&#39;StyleTime:&#39;, StyleTime)  </span><br></pre></td></tr></table></figure>

<ul>
<li>方法二：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">now &#x3D; datetime.datetime.now()                                 # 获得当前时间，这是时间数组格式</span><br><span class="line">StyleTime &#x3D; now.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)                 # 转换为指定的格式</span><br><span class="line">print(&#39;StyleTime:&#39;, StyleTime)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">StyleTime: 2017-07-02 00:16:30</span><br></pre></td></tr></table></figure>

<h3 id="获得三天前的时间"><a href="#获得三天前的时间" class="headerlink" title="获得三天前的时间"></a>获得三天前的时间</h3><ul>
<li>方法:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">threeDayAgo &#x3D; (datetime.datetime.now() - datetime.timedelta(days &#x3D; 3))   # 先获得时间数组格式的日期</span><br><span class="line">timeStamp &#x3D; int(time.mktime(threeDayAgo.timetuple()))                    # 转换为时间戳</span><br><span class="line">threeDayAgo &#x3D; threeDayAgo.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)                  # 转换为其他字符串格式</span><br><span class="line">print(&#39;threeDayAgo:&#39;, threeDayAgo)</span><br></pre></td></tr></table></figure>

<p>timedelta()的参数有:days, seconds, microseconds, milliseconds, minutes, hours, weeks</p>
<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">threeDayAgo: 2017-06-29 00:21:04</span><br></pre></td></tr></table></figure>

<h3 id="给定时间戳-计算该时间的几天前时间"><a href="#给定时间戳-计算该时间的几天前时间" class="headerlink" title="给定时间戳,计算该时间的几天前时间:"></a>给定时间戳,计算该时间的几天前时间:</h3><ul>
<li>方法:</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import datetime</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">timeStamp &#x3D; 1498926852</span><br><span class="line">dateArray &#x3D; datetime.datetime.fromtimestamp(timeStamp)  # 先转换为datetime</span><br><span class="line">threeDayAgo &#x3D; dateArray - datetime.timedelta(days&#x3D;3)</span><br><span class="line">print(&#39;threeDayAgo:&#39;, threeDayAgo)</span><br></pre></td></tr></table></figure>

<ul>
<li>输出结果：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">threeDayAgo: 2017-06-28 16:34:12</span><br></pre></td></tr></table></figure>

<p>参考上面，可以转换为其他的任意格式</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Kafka核心技术与实战》 学习笔记 1</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8AKafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</url>
    <content><![CDATA[<h3 id="什么是-Kafka"><a href="#什么是-Kafka" class="headerlink" title="什么是 Kafka"></a>什么是 Kafka</h3><pre><code>Apache Kafka 是一款开源的消息引擎系统。
</code></pre>
<h3 id="Kafka-消息格式"><a href="#Kafka-消息格式" class="headerlink" title="Kafka 消息格式"></a>Kafka 消息格式</h3><pre><code>Kafka 使用的是纯二进制字节序列。
</code></pre>
<h3 id="Kafka-支持的消息引擎模型"><a href="#Kafka-支持的消息引擎模型" class="headerlink" title="Kafka 支持的消息引擎模型"></a>Kafka 支持的消息引擎模型</h3><pre><code>Kafka 同时支持两种消息引擎模型，点对点模型和发布 / 订阅模型。
</code></pre>
<h3 id="Topic-含义"><a href="#Topic-含义" class="headerlink" title="Topic 含义"></a>Topic 含义</h3><pre><code>在 Kafka 中，发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至是每类数据都创建专属的主题。
</code></pre>
<span id="more"></span>

<h3 id="Producer-和-Consumer-含义"><a href="#Producer-和-Consumer-含义" class="headerlink" title="Producer 和 Consumer 含义"></a>Producer 和 Consumer 含义</h3><pre><code>向主题发布消息的客户端应用程序称为生产者（Producer），生产者程序通常持续不断地向一个或多个主题发送消息，
而订阅这些主题消息的客户端应用程序就被称为消费者（Consumer）。
和生产者类似，消费者也能够同时订阅多个主题的消息。生产者和消费者统称为客户端（Clients）。
</code></pre>
<h3 id="Broker-含义"><a href="#Broker-含义" class="headerlink" title="Broker 含义"></a>Broker 含义</h3><pre><code>Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成，
Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。

虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，
这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。
这其实就是 Kafka 提供高可用的手段之一。
</code></pre>
<h3 id="Replication-含义"><a href="#Replication-含义" class="headerlink" title="Replication 含义"></a>Replication 含义</h3><pre><code>实现高可用的另一个手段就是备份机制（Replication）。
备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝在 Kafka 中被称为副本（Replica）。

Kafka 定义了两类副本：领导者副本（Leader Replica）和追随者副本（Follower Replica）。
前者对外提供服务，这里的对外指的是与客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互。

副本的工作机制也很简单：生产者总是向领导者副本写消息；而消费者总是从领导者副本读消息。
至于追随者副本，它只做一件事：向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。
</code></pre>
<h3 id="Partitioning-含义"><a href="#Partitioning-含义" class="headerlink" title="Partitioning 含义"></a>Partitioning 含义</h3><pre><code>Kafka 中的分区机制指的是将每个主题划分成多个分区（Partition），每个分区是一组有序的消息日志。
生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，
这条消息要么在分区 0 中，要么在分区 1 中。
Kafka 的分区编号是从 0 开始的，如果 Topic 有 100 个分区，那么它们的分区号就是从 0 到 99。
</code></pre>
<h3 id="副本如何与分区联系在一起"><a href="#副本如何与分区联系在一起" class="headerlink" title="副本如何与分区联系在一起"></a>副本如何与分区联系在一起</h3><pre><code>副本是在分区这个层级定义的。
每个分区下可以配置若干个副本，其中只能有 1 个领导者副本和 N-1 个追随者副本。
生产者向分区写入消息，每条消息在分区中的位置信息由一个叫位移（Offset）的数据来表征。
分区位移总是从 0 开始，假设一个生产者向一个空分区写入了 10 条消息，那么这 10 条消息的位移依次是 0、1、2、......、9。
</code></pre>
<h3 id="Kafka-的三层消息架构"><a href="#Kafka-的三层消息架构" class="headerlink" title="Kafka 的三层消息架构"></a>Kafka 的三层消息架构</h3><pre><code>- 第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。
- 第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。
- 第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。
- 最后，客户端程序只能与分区的领导者副本进行交互。
</code></pre>
<h3 id="Broker-如何持久化数据"><a href="#Broker-如何持久化数据" class="headerlink" title="Broker 如何持久化数据"></a>Broker 如何持久化数据</h3><pre><code>Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。
因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。
Kafka 要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。
在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，
当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。
Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。
</code></pre>
<h3 id="Kafka-中实现-P2P-模型的方法"><a href="#Kafka-中实现-P2P-模型的方法" class="headerlink" title="Kafka 中实现 P2P 模型的方法"></a>Kafka 中实现 P2P 模型的方法</h3><pre><code>在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。
所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。
这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。
为什么要引入消费者组呢？主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。
另外这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。
消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更酷的是它们还能彼此协助。
假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。
这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。
</code></pre>
<h3 id="消费者位移"><a href="#消费者位移" class="headerlink" title="消费者位移"></a>消费者位移</h3><pre><code>每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，
这个字段就是消费者位移（Consumer Offset）。
注意，这和上面所说的位移完全不是一个概念。
上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。
而消费者位移则不同，它可能是随时变化的。
另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。
</code></pre>
<h3 id="术语示意图"><a href="#术语示意图" class="headerlink" title="术语示意图"></a>术语示意图</h3><p align='center'>
    <img data-src='https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8AKafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_1.jpg'>
</p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>uWSGI、WSGI 和 uwsgi</title>
    <url>/uWSGI%E3%80%81WSGI-%E5%92%8C-uwsgi/</url>
    <content><![CDATA[<h3 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h3><p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/uWSGI%E3%80%81WSGI%20%E5%92%8C%20uwsgi_1.jpg" alt="image"></p>
<span id="more"></span>

<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/uWSGI%E3%80%81WSGI%20%E5%92%8C%20uwsgi_2.jpg" alt="image"></p>
<p><img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/uWSGI%E3%80%81WSGI%20%E5%92%8C%20uwsgi_3.jpg" alt="image"></p>
<h4 id="WSGI"><a href="#WSGI" class="headerlink" title="WSGI"></a>WSGI</h4><p>wsgi server（比如 uWSGI）要和 wsgi application（比如 django ）交互，uWSGI 需要将过来的请求转给 django 处理，那么 uWSGI 和 django 的交互和调用就需要一个统一的规范，这个规范就是 WSGI。</p>
<p>WSGI，全称 Web Server Gateway Interface，或者 Python Web Server Gateway Interface，是为 Python 语言定义的 Web 服务器和 Web 应用程序或框架之间的一种简单而通用的接口。自从 WSGI 被开发出来以后，许多其它语言中也出现了类似接口。</p>
<p>WSGI 的官方定义是，the Python Web Server Gateway Interface。从名字就可以看出来，这东西是一个 Gateway，也就是网关。网关的作用就是在协议之间进行转换。</p>
<p>WSGI 是作为 Web 服务器与 Web 应用程序或应用框架之间的一种低级别的接口，以提升可移植 Web 应用开发的共同点。WSGI 是基于现存的 CGI 标准而设计的。</p>
<h4 id="uWSGI"><a href="#uWSGI" class="headerlink" title="uWSGI"></a>uWSGI</h4><p>uWSGI 是一个 Web 服务器，它实现了 WSGI 协议、uwsgi、http 等协议。Nginx 中 HttpUwsgiModule 的作用是与 uWSGI 服务器进行交换。</p>
<h4 id="uwsgi"><a href="#uwsgi" class="headerlink" title="uwsgi"></a>uwsgi</h4><p>与 WSGI 一样是一种通信协议，是 uWSGI 服务器的独占协议，用于定义传输信息的类型（type of information），每一个 uwsgi packet 前 4byte 为传输信息类型的描述，与 WSGI 协议是两种东西，据说该协议是 fcgi 协议的 10 倍快。</p>
<h4 id="FastCgi-协议，-uwsgi-协议与-http-协议有什么用？"><a href="#FastCgi-协议，-uwsgi-协议与-http-协议有什么用？" class="headerlink" title="FastCgi 协议， uwsgi 协议与 http 协议有什么用？"></a>FastCgi 协议， uwsgi 协议与 http 协议有什么用？</h4><p>nginx 和下游服务器交互就必须使用同一个协议，只要大家沟通好使用哪个协议，就可以正常运行了。</p>
<p>这三种协议就是 nginx 为了与下游服务器交互事先约定好的协议。</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 1</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/</url>
    <content><![CDATA[<h3 id="数据结构：快速的-Redis-有哪些慢操作？"><a href="#数据结构：快速的-Redis-有哪些慢操作？" class="headerlink" title="数据结构：快速的 Redis 有哪些慢操作？"></a>数据结构：快速的 Redis 有哪些慢操作？</h3><hr>
<ul>
<li>Redis 表现突出的原因</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
一方面，这是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。<br>
另一方面，这要归功于它的数据结构。
这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，
所以高效的数据结构是 Redis 快速处理数据的基础。
</pre>

<ul>
<li>底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。</li>
</ul>
<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_1.jpg" width="500" align=center>
</div><br>

<span id="more"></span>

<ul>
<li>键和值用什么结构组织？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。<br>
一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。
所以，我们常说，一个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。<br>
哈希桶中的 entry 元素中保存了 \*key 和 \*value 指针，分别指向了实际的键和值，
这样一来，即使值是一个集合，也可以通过*value指针被查找到。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_2.jpg" width="500">
</div><br>

<ul>
<li>为什么哈希表操作变慢了？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
哈希表的冲突问题和 rehash 可能带来的操作阻塞。<br>
Redis 解决哈希冲突的方式，就是链式哈希。<br>
但是，这里依然存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。<br>
如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，
这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。<br>
对于追求“快”的 Redis 来说，这是不太能接受的。<br>
所以，Redis 会对哈希表做 rehash 操作。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_3.jpg" width="500">
</div><br>

<ul>
<li>哈希表做 rehash</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
rehash 也就是增加现有的哈希桶数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。<br>
其实，为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：
哈希表 1 和哈希表 2。
一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。
随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：
  1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
  2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
  3. 释放哈希表 1 的空间。
<br>到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用。<br>
这个过程看似简单，但是第二步涉及大量的数据拷贝，
如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。
此时，Redis 就无法快速访问数据了。<br>
为了避免这个问题，Redis 采用了渐进式 rehash。
</pre>

<ul>
<li>渐进式 rehash</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求。<br>
每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中。<br>
等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如下图所示：
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_4.jpg" width="500">
</div><br>

<ul>
<li>对于 String 类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。</li>
<li>压缩列表</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
压缩列表实际上类似于一个数组，数组中的每一个元素都对应保存一个数据。<br>
和数组不同的是，压缩列表在表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；
压缩列表在表尾还有一个 zlend，表示列表结束。<br>
在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。<br>
而查找其他元素时，就没有这么高效了，只能逐个查找，此时的复杂度就是 O(N) 了。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_5.jpg" width="500">
</div><br>

<ul>
<li>跳表</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。<br>
具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位，如下图所示：
当数据量很大时，跳表的查找复杂度就是 O(logN)。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_6.jpg" width="500">
</div><br>

<ul>
<li>数据结构的时间复杂度</li>
</ul>
<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%201_7.jpg" width="500">
</div>

<ul>
<li><p>四句口诀</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
</li>
<li><p>单元素操作</p>
</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指每一种集合类型对单个数据实现的增删改查操作。<br>
例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。<br>
这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；<br>
Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。<br>
这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，
例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。<br>
此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。
</pre>

<ul>
<li>范围操作</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指集合类型中的遍历操作，可以返回集合中的所有数据。<br>
比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。<br>
这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。<br>
Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。<br>
这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。
</pre>

<ul>
<li>统计操作</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。<br>
这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，
这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。
</pre>

<ul>
<li>例外情况</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。<br>
这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，
这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。
</pre>

<ul>
<li>复杂度较高的 List 类型，它的两种底层实现结构：双向链表和压缩列表的操作复杂度都是 O(N)。因此，<strong>因地制宜地使用 List 类型</strong>。</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 2</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/</url>
    <content><![CDATA[<h3 id="高性能IO模型：为什么单线程Redis能那么快？"><a href="#高性能IO模型：为什么单线程Redis能那么快？" class="headerlink" title="高性能IO模型：为什么单线程Redis能那么快？"></a>高性能IO模型：为什么单线程Redis能那么快？</h3><hr>
<ul>
<li>Redis 单线程的理解</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写（数据读写）是由一个线程来完成的，
这也是 Redis 对外提供键值存储服务的主要流程。<br>
但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。
</pre>

<ul>
<li>Redis 为什么用单线程？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
多线程编程模式面临共享资源的并发访问控制问题。<br>
并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，
比如说，只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果：
    即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加。<br>
而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。<br>
为了避免这些问题，Redis 直接采用了单线程模式。
</pre>

<ul>
<li>单线程 Redis 为什么那么快？</li>
</ul>
<span id="more"></span>

<pre style="font-size:0.9em; color:#666666;">
一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，
例如哈希表和跳表，这是它实现高性能的一个重要原因。<br>
另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率。
</pre>

<ul>
<li>基本 IO 模型与阻塞点</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
以 Get 请求为例，为了处理一个 Get 请求，
需要监听客户端请求（bind/listen），
和客户端建立连接（accept），
从 socket 中读取请求（recv），
解析客户端发送请求（parse），
根据请求类型读取键值数据（get），
最后给客户端返回结果，即向 socket 中写回数据（send）。<br>
下图显示了这一过程，其中，bind/listen、accept、recv、parse 和 send 属于网络 IO 处理，而 get 属于键值数据操作。
既然 Redis 是单线程，那么，最基本的一种实现是在一个线程中依次执行上面说的这些操作。

但是，在这里的网络 IO 操作中，有潜在的阻塞点，分别是 accept() 和 recv()。<br>
当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept() 函数这里，
导致其他客户端无法和 Redis 建立连接。<br>
类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据一直没有到达，Redis 也会一直阻塞在 recv()。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%202_1.jpg" width="500">
</div><br>

<ul>
<li>非阻塞模式</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
在 socket 模型中，不同操作调用后会返回不同的套接字类型。<br>
socket() 方法会返回主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。<br>
最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字。<br>
针对监听套接字，我们可以设置非阻塞模式：
    当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其他操作，而不用一直等待。
    但是，你要注意的是，调用 accept() 时，已经存在监听套接字了
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%202_2.jpg" width="500">
</div><br>

<ul>
<li>基于多路复用的高性能 I/O 模型</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。<br>
简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。<br>
内核会一直监听这些套接字上的连接请求或数据请求。<br>
一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。<br>
下图就是基于多路复用的 Redis IO 模型。
图中的多个 FD 就是刚才所说的多个套接字。<br>
Redis 网络框架调用 epoll 机制，让内核监听这些套接字。
此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，
也就是说，不会阻塞在某一个特定的客户端请求处理上。<br>
正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。<br>
为了在请求到达时能通知到 Redis 线程，select/epoll 提供了基于事件的回调机制，
即针对不同事件的发生，调用相应的处理函数。<br>
select/epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件。

这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。<br>
这样一来，Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 资源浪费。<br>
同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。<br>
因为 Redis 一直在对事件队列进行处理，所以能及时响应客户端请求，提升 Redis 的响应性能。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%202_3.jpg" width="500">
</div>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 3</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/</url>
    <content><![CDATA[<h3 id="AOF日志：宕机了，Redis如何避免数据丢失？"><a href="#AOF日志：宕机了，Redis如何避免数据丢失？" class="headerlink" title="AOF日志：宕机了，Redis如何避免数据丢失？"></a>AOF日志：宕机了，Redis如何避免数据丢失？</h3><hr>
<ul>
<li>Redis 的持久化主要有两大机制，即 AOF(Append Only File) 日志和 RDB(Redis DataBase) 快照。</li>
<li>AOF 日志是如何实现的？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
AOF 日志写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_1.jpg" width="500">
</div><br>

<span id="more"></span>

<ul>
<li>AOF 为什么要先执行命令再记日志呢？</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，
而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。<br>
以 Redis 收到 “set testkey testvalue” 命令后记录的日志为例，看看 AOF 日志的内容。
其中，“*3” 表示当前命令有三个部分，每部分都是由 “$+数字” 开头，后面紧跟着具体的命令、键或值。
这里，“数字” 表示这部分中的命令、键或值一共有多少字节。
例如，“$3 set” 表示这部分有 3 个字节，也就是 “set” 命令。<br>
为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。
所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。<br>
而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，
否则，系统就会直接向客户端报错。<br>
所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。<br>
除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_2.jpg" width="500">
</div><br>

<ul>
<li>AOF 两个潜在的风险</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。<br>
如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，
但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。<br>
其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。<br>
这是因为，AOF 日志也是在<strong>主线程</strong>中执行的，
如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。
</pre>

<ul>
<li>三种写回策略</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选。<br>
<ul>
  <li>Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；</li>
  <li>Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；</li>
  <li>No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。</li>
</ul>
针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。
<ul>
  <li>“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能；</li>
  <li>“每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，
虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。
所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。</li>
  <li>虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，
但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了；</li>
</ul>
</pre>

<ul>
<li>三种策略的写回时机对比</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
想要获得高性能，就选择 No 策略；<br>
如果想要得到高可靠性保证，就选择 Always 策略；<br>
如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_3.jpg" width="500">
</div><br>

<ul>
<li> AOF 文件过大带来的性能问题</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
这里的“性能问题”，主要在于以下三个方面：<br>
  一是，文件系统本身对文件大小有限制，无法保存过大的文件；<br>
  二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；<br>
  三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，
        如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。
</pre>

<ul>
<li>AOF 重写机制</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
AOF 重写机制指的是，对过大的 AOF 文件进行重写，以此来压缩 AOF 文件的大小。<br>
具体的实现是：检查当前键值数据库中的键值对，记录键值对的最终状态，
从而实现对某个键值对重复操作后产生的多条操作记录压缩成一条的效果。进而实现压缩 AOF 文件的大小。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_4.jpg" width="500">
</div><br>

<ul>
<li>AOF 重写会阻塞吗?</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
和 AOF 日志由主线程写回不同，重写过程是由后台线程 bgrewriteaof 来完成的，
这也是为了避免阻塞主线程，导致数据库性能下降。<br>
</pre>

<ul>
<li>AOF 重写过程</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
重写的过程总结为“一个拷贝，两处日志”。<br>
一个拷贝：
    每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。<br>
    此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。<br>
    然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。<br>
两处日志：
    因为主线程未阻塞，仍然可以处理新来的操作。<br>
    此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。
    这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。<br>
    而第二处日志，
    就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。
    这样，重写日志也不会丢失最新的操作。
    等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。<br>
    此时，我们就可以用新的 AOF 文件替代旧文件了。
    
总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；
然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。
而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%203_5.jpg" width="500">
</div><br>

<ul>
<li>对于开启 HugePages 的操作系统，父进程申请内存时阻塞的概率将会大大提高，Hugepages 在实际使用 Redis 并需要持久化时是建议关掉的。</li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>极客时间 - 《Redis核心技术与实战》 学习笔记 4</title>
    <url>/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4/</url>
    <content><![CDATA[<h3 id="内存快照：宕机后，Redis如何实现快速恢复？"><a href="#内存快照：宕机后，Redis如何实现快速恢复？" class="headerlink" title="内存快照：宕机后，Redis如何实现快速恢复？"></a>内存快照：宕机后，Redis如何实现快速恢复？</h3><hr>
<ul>
<li>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
save：在主线程中执行，会导致阻塞；
bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。
</pre>

<ul>
<li>Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。</li>
</ul>
<span id="more"></span>

<pre style="font-size:0.9em; color:#666666;">
简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。<br>
bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。<br>
此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。<br>
但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。<br>
然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%204_1.jpg" width="500">
</div><br>

<ul>
<li>如果频繁地执行全量快照，也会带来两方面的开销。</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，
前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。<br>
另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。<br>
虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，
而且主线程的内存越大，阻塞时间越长。<br>
如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。
</pre>

<ul>
<li>Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。<br>
这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。<br>
而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，
因此，就不会出现文件过大的情况了，也可以避免重写开销。<br>
如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，
等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。
</pre>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4%20-%20%E3%80%8ARedis%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E3%80%8B%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%204_2.jpg" width="500">
</div><br>

<ul>
<li>RDB 优势在于，可以快速恢复数据库，也就是只需要把 RDB 文件直接读入内存，避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。缺点是频繁快照很耗资源<br>
<br></li>
<li>三点建议</li>
</ul>
<pre style="font-size:0.9em; color:#666666;">
1. 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；<br>
2. 如果允许分钟级别的数据丢失，可以只使用 RDB；<br>
3. 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。
</pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>递归反转栈</title>
    <url>/%E9%80%92%E5%BD%92%E5%8F%8D%E8%BD%AC%E6%A0%88/</url>
    <content><![CDATA[<h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><p>翻转栈的所有元素，例如输入栈 {1,2,3,4,5}，其中 1 处在栈顶，翻转之后的栈为 {5,4,3,2,1}，其中，5 处在栈顶，注意使用递归</p>
<h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><p>递归算法不需要考虑中间过程，上一层的递归可以直接使用下一层的递归结果，即假设下一层已经完成了我们的要求就行了，最后只需要考虑最后一层递归退出的条件就行了</p>
<span id="more"></span>

<div style="text-align:center">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/%E9%80%92%E5%BD%92%E5%8F%8D%E8%BD%AC%E6%A0%88.png" width="2000">
</div><br>

<p>递归函数结束的条件：是当栈为空或者栈里只有一个元素的时候，return。</p>
<h3 id="解题代码"><a href="#解题代码" class="headerlink" title="解题代码"></a>解题代码</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reverse_stack</span>(<span class="params">s</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> s:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(s) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    temp1 = s.pop()</span><br><span class="line">    reverse_stack(s)</span><br><span class="line">    temp2 = s.pop()</span><br><span class="line">    reverse_stack(s)</span><br><span class="line">    s.append(temp1)</span><br><span class="line">    reverse_stack(s)</span><br><span class="line">    s.append(temp2)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    stack = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">    reverse_stack(stack)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;翻转后出栈的顺序为：&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(stack)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>DS&amp;A</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>DS&amp;A</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 面试知识点总结（上）</title>
    <url>/Redis-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Redis-和-Memecache-的区别是什么？"><a href="#Redis-和-Memecache-的区别是什么？" class="headerlink" title="Redis 和 Memecache 的区别是什么？"></a>Redis 和 Memecache 的区别是什么？</h1><pre><code>1. Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memecache 支持简单的数据类型 String
2. Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中
3. Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的
4. Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型
</code></pre>
<h1 id="Redis-常见数据结构以及使用场景分析？"><a href="#Redis-常见数据结构以及使用场景分析？" class="headerlink" title="Redis 常见数据结构以及使用场景分析？"></a>Redis 常见数据结构以及使用场景分析？</h1><pre><code>1. String 字符串
   字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型，而且其他几种数据结构都是在字符串类型基础上构建的。
   常用在缓存、计数、共享 Session、限速等。
2. Hash 哈希
   在 Redis 中，哈希类型是指键值本身又是一个键值对结构，形如 value=&#123;&#123;field1，value1&#125;，...&#123;fieldN，valueN&#125;&#125;。
   哈希可以用来存放用户信息，比如实现购物车。
3. List 列表
   列表（list）类型是用来存储多个有序的字符串。
   可以做简单的消息队列的功能。另外，可以利用 lrange 命令，做基于 Redis 的分页功能，性能极佳，用户体验好。
4. Set 集合
   集合（set）类型也是用来保存多个的字符串元素，但集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素。
   利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
5. Sorted Set 有序集合
   Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。
   可以做排行榜应用，取 TOP N 操作

除此之外还有 3 个高级数据结构
1. Bitmaps bitmaps 应用于信息状态统计
2. HyperLogLog 应用于基数统计
3. GEO 应用于地理位置计算
</code></pre>
<span id="more"></span>

<h1 id="Redis-String-的实现原理"><a href="#Redis-String-的实现原理" class="headerlink" title="Redis String 的实现原理"></a>Redis String 的实现原理</h1><pre><code>Redis 内部 String 类型采用 SDS（simple dynamic string）表示
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct sdshdr &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; buf 已占用长度</span><br><span class="line">    int len;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; buf 剩余可用长度</span><br><span class="line">    int free;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 实际保存字符串数据的地方</span><br><span class="line">    char buf[];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
对比 C 字符串， SDS 有以下特性：
    1. 可以高效地执行长度计算（strlen） // 直接取 len 字段
    2. 防止 buf 存储内容溢出的问题 // 首先判断 free 字段是否足够
    3. 可以高效地执行追加操作（append） // 通过预分配空间，free 字段
    4. 二进制安全 // 不以 \0 做为结尾标识
</code></pre>
<h1 id="Redis-List-的实现原理"><a href="#Redis-List-的实现原理" class="headerlink" title="Redis List 的实现原理"></a>Redis List 的实现原理</h1><pre><code>在 Redis 3.2 之前，List 底层采用了 ZipList 和 LinkedList 实现的，在 3.2 之后，List 底层采用了 QuickList。
Redis 3.2 之前，初始化的 List 使用的 ZipList，当以下两个条件任意一个不满足时，则会被转换成 LinkedList：
    1. List 中存储的每个元素的长度小于 64byte（可以通过配置文件修改）
    2. 元素个数小于 512（可以通过配置文件修改）

ZipList 为节省内存而设计，内存是连续的
没有维护双向指针：prev next，而是存储上一个 entry（可以理解为一个数据）的长度和 当前 entry 的长度，通过长度推算下一个元素在什么地方。
最大的缺点是是连锁更新问题，以时间换空间。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-ZipList.png'>
</p>

<table>
<thead>
<tr>
<th align="center">属性</th>
<th align="center">类型</th>
<th align="center">长度</th>
<th align="center">用途</th>
</tr>
</thead>
<tbody><tr>
<td align="center">zlbytes</td>
<td align="center">uint_32t</td>
<td align="center">4B</td>
<td align="center"><strong>记录整个压缩列表占用的内存字节数</strong>：在对压缩列表进行内存重分配， 或者计算 zlend的位置时使用</td>
</tr>
<tr>
<td align="center">zltail</td>
<td align="center">uint_32t</td>
<td align="center">4B</td>
<td align="center"><strong>记录压缩列表表尾节点距离压缩列表的起始地址有多少字节</strong>：通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址</td>
</tr>
<tr>
<td align="center">zllen</td>
<td align="center">uint_16t</td>
<td align="center">2B</td>
<td align="center"><strong>记录了压缩列表包含的节点数量</strong>： 当这个属性的值小于UINT16_ MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量；当这个值等于 UINT16_MAX 时，节点的真实数量需要遍历整个压缩列表才能计算得出</td>
</tr>
<tr>
<td align="center">entryX</td>
<td align="center">列表节点</td>
<td align="center">不定</td>
<td align="center">压缩列表包含的各个节点，<strong>节点的长度由节点保存的内容决定</strong></td>
</tr>
<tr>
<td align="center">zlend</td>
<td align="center">uint_8t</td>
<td align="center">1B</td>
<td align="center">特殊值 0xFF （十进制 255 ），<strong>用于标记压缩列表的末端</strong></td>
</tr>
</tbody></table>
<pre><code>LinkedList 是由一系列不连续的内存块通过指针连接起来的双向链表。
缺点是它的内存开销比较大。首先，它在每个节点上除了要保存数据之外，还要额外保存两个指针。
其次，它的各个节点是单独的内存块，地址不连续，节点多了容易产生内存碎片。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-LinkedList.png'>
</p>

<pre><code>QuickList 是一个 ZipList 组成的双向链表。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-QuickList.png'>
</p>

<h1 id="Redis-Hash-的实现原理"><a href="#Redis-Hash-的实现原理" class="headerlink" title="Redis Hash 的实现原理"></a>Redis Hash 的实现原理</h1><pre><code>参考：
    1. [渐进式 rehash](http://redisbook.com/preview/dict/incremental_rehashing.html)

Redis 的哈希对象的底层存储可以使用 ZipList 和 HashTable。
当 Hash 对象可以同时满足一下两个条件时，哈希对象使用 ZipList 编码：
    1. 哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节（可以通过配置文件修改）
    2. 哈希对象保存的键值对数量小于 512 个（可以通过配置文件修改）

HashTable 编码的哈希表对象底层使用字典数据结构。
Redis 解决哈希冲突的方式，是链式哈希。
这里存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。
如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长。
所以，Redis 会对哈希表做 rehash 操作。

渐进式的 rehash
rehash 使用两个哈希表 1 和哈希表 2。
随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步：
  1. 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；
  2. 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中；
  3. 释放哈希表 1 的空间。
在第 2 步 Redis 不是一次性把全部数据 rehash 成功，这样会导致 Redis 对外服务停止，Redis 内部为了处理这种情况采用渐进式的 rehash。
Redis 将所有的 rehash 的操作分成多步进行，直到都 rehash 完成，
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-HashTable.jpg'>
</p>

<h1 id="Redis-Set-的实现原理"><a href="#Redis-Set-的实现原理" class="headerlink" title="Redis Set 的实现原理"></a>Redis Set 的实现原理</h1><pre><code>Set 集合采用 intset（整数集合）和 HashTable 两种方式来实现，当满足以下两个条件的时候，采用 intset 实现，
一旦有一个条件不满足时则采用 HashTable 来实现：
    1. Set 集合中的所有元素都为整数
    2. Set 集合中的元素个数不大于 512（可以通过配置文件修改）
</code></pre>
<h1 id="Redis-Sorted-Set-的实现原理"><a href="#Redis-Sorted-Set-的实现原理" class="headerlink" title="Redis Sorted Set 的实现原理"></a>Redis Sorted Set 的实现原理</h1><pre><code>参考：
    1. [Redis 为什么用跳表而不用平衡树？](https://juejin.cn/post/6844903446475177998)

Zset 底层同样采用了两种方式来实现，分别是 ZipList 和 SkipList。当同时满足以下两个条件时，采用 ZipList 实现；反之采用 SkipList 实现：
    1. Zset 中保存的元素个数小于 128（可以通过配置文件修改）
    2. Zset 中保存的所有元素长度小于 64byte（可以通过配置文件修改）

采用 ZipList 的实现原理
    和 List 的底层实现有些相似，对于 Zset 不同的是，其存储是以键值对的方式依次排列，键存储的是实际 value，值存储的是 value 对应的分值。

采用 SkipList 的实现原理
    SkipList 编码的 Zset 底层为一个被称为 zset 的结构体，这个结构体中包含一个字典和一个跳跃表。
    跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。
    字典保存从 member 到 score 的映射，这样就可以用 O(1)​ 的复杂度来查找 member 对应的 score 值。
    跳表是一种并联的链表，它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供 O(logN) 的时间复杂度。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（上）/Redis-SkipList.jpg'>
</p>

<pre><code>为什么用的跳表不是红黑树?
    根据作者的原话：
    1. 跳表使用的内存不是固定的，可以通过调整参数，使占用的内存低于 btree
    2. Zset 通常是 Zrange 或 Zrevrange 的操作，跳表至少与其他类型的平衡树性能一样好
    3. 跳表实现简单
</code></pre>
<h1 id="Redis-压缩采用什么算法"><a href="#Redis-压缩采用什么算法" class="headerlink" title="Redis 压缩采用什么算法?"></a>Redis 压缩采用什么算法?</h1><pre><code>对 ziplist 使用 LZF 算法进行压缩，可以选择压缩深度。
</code></pre>
<h1 id="Redis-中的-Bitmaps"><a href="#Redis-中的-Bitmaps" class="headerlink" title="Redis 中的 Bitmaps"></a>Redis 中的 Bitmaps</h1><pre><code>bitmaps 不是一个真实的数据结构。而是 String 类型上的一组面向 bit 操作的集合。
常用命令：
    setbit key offset value
    getbit key offset
场景举例：
    统计活跃用户（用户登陆情况）
        使用日期作为 key，然后用户 id 为 offset，如果当日活跃过就设置为 1
    统计每天某一部电影是否被点播 统计每天有多少部电影被点播 统计每周/月/年有多少部电影被点播 统计年度哪部电影没有被点播
        日期作为 key，然后电影 id 为 offset，如果点播过就设置为 1
</code></pre>
<h1 id="Redis-中的-HyperLogLog"><a href="#Redis-中的-HyperLogLog" class="headerlink" title="Redis 中的 HyperLogLog"></a>Redis 中的 HyperLogLog</h1><pre><code>Redis HyperLogLog 是用来做基数统计的算法，优点是在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。
但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。

比如实现 统计 APP 或网页的一个页面，每天有多少用户点击进入的次数，同一个用户的反复点击进入记为 1 次。
命令有：
    PFADD key element [element ...]
        添加指定元素到 HyperLogLog 中。
    PFCOUNT key [key ...]
        返回给定 HyperLogLog 的基数估算值。
    PFMERGE destkey sourcekey [sourcekey ...]
        将多个 HyperLogLog 合并为一个 HyperLogLog
</code></pre>
<h1 id="Redis-客户端和服务器之间通信才用什么协议？"><a href="#Redis-客户端和服务器之间通信才用什么协议？" class="headerlink" title="Redis 客户端和服务器之间通信才用什么协议？"></a>Redis 客户端和服务器之间通信才用什么协议？</h1><pre><code>Redis 客户端使用基于 TCP 的 RESP（Redis 的序列化协议，Redis Serialization Protocol）协议与 Redis 的服务器端进行通信。
类型通过首个字节区分（+,-,:,$,*），每一部分结束时，Redis 统一使用“\r\n”表示结束。
</code></pre>
<h1 id="Redis-过期策略"><a href="#Redis-过期策略" class="headerlink" title="Redis 过期策略"></a>Redis 过期策略</h1><pre><code>1. 定期删除，Redis 默认每隔 100ms 检查，是否有过期的 key，有过期 key 则删除。
   需要说明的是，Redis 不是每隔 100ms 将所有的 key 检查一次，而是随机抽取进行检查(如果每隔 100ms，全部 key 进行检查，Redis 岂不是卡死)。
   因此，如果只采用定期删除策略，会导致很多 key 到时间没有删除。
2. 惰性删除，也就是说在你获取某个 key 的时候，Redis 会检查一下，这个 key 如果设置了过期时间那么是否过期，如果过期了此时就会删除。

过期策略存在的问题，由于 Redis 定期删除是随机抽取检查，不可能扫描清除掉所有过期的 key 并删除，某些 key 由于未被请求，惰性删除也未触发。
这样 Redis 的内存占用会越来越高，此时就需要内存淘汰机制。
</code></pre>
<h1 id="Redis-内存淘汰机制"><a href="#Redis-内存淘汰机制" class="headerlink" title="Redis 内存淘汰机制"></a>Redis 内存淘汰机制</h1><pre><code>- no-eviction：默认策略，不淘汰数据；大部分写命令都将返回错误（DEL 等少数除外）
- allkeys-lru：从所有数据中根据 LRU 算法挑选数据淘汰
- volatile-lru：从设置了过期时间的数据中根据 LRU 算法挑选数据淘汰
- allkeys-random：从所有数据中随机挑选数据淘汰
- volatile-random：从设置了过期时间的数据中随机挑选数据淘汰
- volatile-ttl：从设置了过期时间的数据中，挑选越早过期的数据进行删除
- allkeys-lfu：从所有数据中根据 LFU 算法挑选数据淘汰（4.0 及以上版本可用）
- volatile-lfu：从设置了过期时间的数据中根据 LFU 算法挑选数据淘汰（4.0 及以上版本可用）
</code></pre>
<h1 id="LRU-与-LFU-的区别"><a href="#LRU-与-LFU-的区别" class="headerlink" title="LRU 与 LFU 的区别"></a>LRU 与 LFU 的区别</h1><pre><code>LFU：Least Recently Used，最近最少使用
LFU：Least Frequently Used，使用频率最少的（最不经常使用的）
如果一条数据仅仅是突然被访问（有可能后续将不再访问），在 LRU 算法下，此数据将被定义为热数据，最晚被淘汰。
但实际生产环境下，我们很多时候需要计算的是一段时间下 key 的访问频率，淘汰此时间段内的冷数据。

LFU 算法相比 LRU，在某些情况下可以提升 数据命中率，使用频率更多的数据将更容易被保留。
</code></pre>
<table>
<thead>
<tr>
<th>对比项</th>
<th>近似LRU算法</th>
<th>LFU 算法</th>
</tr>
</thead>
<tbody><tr>
<td>最先过期的数据</td>
<td>最近未被访问的</td>
<td>最近一段时间访问的最少的</td>
</tr>
<tr>
<td>适用场景</td>
<td>数据被连续访问场景</td>
<td>数据在一段时间内被连续访问</td>
</tr>
<tr>
<td>缺点</td>
<td>新增 key 将占据缓存</td>
<td>历史访问次数超大的 key 淘汰速度取决于 lfu-decay-time</td>
</tr>
</tbody></table>
<h1 id="Redis-的-LRU-实现"><a href="#Redis-的-LRU-实现" class="headerlink" title="Redis 的 LRU 实现"></a>Redis 的 LRU 实现</h1><pre><code>Redis 中的 LRU 与常规的 LRU 实现并不相同，常规 LRU 会准确的淘汰掉队头的元素，但是 Redis 的 LRU 并不维护队列，
只是根据配置的策略要么从所有的 key 中随机选择 N 个（N 可以配置）要么从所有的设置了过期时间的 key 中选出 N 个键，
然后再从这 N 个键中选出最久没有使用的一个 key 进行淘汰。

为什么要使用近似 LRU？
1. 性能问题，由于近似 LRU 算法只是最多随机采样 N 个 key 并对其进行排序，如果精准需要对所有 key 进行排序，这样近似 LRU 性能更高
2. 内存占用问题，Redis 对内存要求很高，会尽量降低内存使用率，如果是抽样排序可以有效降低内存的占用
3. 实际效果基本相等，如果请求符合长尾法则，那么真实 LRU 与 Redis LRU 之间表现基本无差异
</code></pre>
<h1 id="如何保证-Redis-中存放的都是热点数据"><a href="#如何保证-Redis-中存放的都是热点数据" class="headerlink" title="如何保证 Redis 中存放的都是热点数据"></a>如何保证 Redis 中存放的都是热点数据</h1><pre><code>限定 Redis 占用的内存，Redis 会根据自身数据淘汰策略，留下热数据到内存。
所以，计算一下热点数据大约占用的内存，然后设置一下 Redis 内存限制，并根据业务场景修改淘汰策略
</code></pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis，面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 面试知识点总结（下）</title>
    <url>/Redis-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    <content><![CDATA[<h1 id="Redis-事务机制"><a href="#Redis-事务机制" class="headerlink" title="Redis 事务机制"></a>Redis 事务机制</h1><pre><code>参考：
    1. [从面试被问到吐血，Redis事务的问题个个触及知识盲区，脸都绿了](https://zhuanlan.zhihu.com/p/156889090)

1. multi —— 开启事务
2.命令入队列
    之后所有的命令都会放入事务队列中，并不会立刻执行。
    如果客户端发送的命令为 EXEC，DISCARD 的其中一个，服务器会立刻执行这个命令。
    对于其它命令，服务器并不会立刻执行，而是将这个命令放入一个事务队列中，然后向客户端返回 QUEUED 回复
3. exec —— 执行事务
4. DISCARD —— 放弃执行

Redis 的事务机制可以保证一致性和隔离性（watch 机制）。
持久性取决于是否开启持久化以及持久化机制，极端情况下还是无法保证。
原子性的情况比较复杂：
    1. 命令入队时就报错，会放弃事务执行，保证原子性
    2. 命令入队时没报错，实际执行时报错，不保证原子性
    3. EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性
      （使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除。
       使用 AOF 恢复实例后，事务操作不会再被执行，从而保证原子性。
    只有当事务中使用的命令语法有误时，原子性得不到保证，在其它情况下，事务都可以原子性执行。
</code></pre>
<span id="more"></span>

<h1 id="Redis-主从同步机制"><a href="#Redis-主从同步机制" class="headerlink" title="Redis 主从同步机制"></a>Redis 主从同步机制</h1><pre><code>参考：
    1. [极客时间《Redis核心技术与实战》06 | 数据同步：主从库如何实现数据一致？](https://time.geekbang.org/column/article/272852)
    2. [一文让你明白Redis主从同步](https://zhuanlan.zhihu.com/p/55532249)

主从模式是最简单的实现高可用的方案，核心就是主从同步。
Redis 的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。

全量同步的原理如下：

1. 从服务器向主服务器发送 sync 命令
2. 收到 sync 命令后，主服务器执行 bgsave 命令，用来生成 rdb 文件，并在一个缓冲区中记录从现在开始执行的写命令。
3. bgsave 执行完成后，将生成的 rdb 文件发送给从服务器，用来给从服务器更新数据
4. 主服务器再将缓冲区记录的写命令发送给从服务器，从服务器执行完这些写命令后，此时的数据库状态便和主服务器一致了。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（下）/Redis-全量同步机制.jpg'>
</p>

<pre><code>上面写的命令是 sync，但是在 Redis 2.8 版本之后已经使用 psync 来替代 sync 了，
原因是 sync 命令非常消耗系统资源，而 psync 的效率更高（可以根据需要增量同步）。

长连接复制：
    长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。

增量复制：
    当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，
    同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。
    repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。
    随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，通常用偏移量来衡量这个偏移距离的大小，
    对主库来说，对应的偏移量就是 master_repl_offset。
    主库接收的新写操作越多，这个值就会越大。
    同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，
    此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。
    正常情况下，这两个偏移量基本相等。
    主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，
    主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。
    在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。
    此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。

主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这需要人工干预，费事费力，还会造成一段时间内服务不可用。
这种方式并不推荐，实际生产中，优先考虑哨兵模式。

优缺点：
   优点：
       1. 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离
       2. Slave 同样可以接受其他 Slaves 的连接和同步请求，这样可以有效地分载 Master 的同步压力
   缺点：
       1. Redis 不具备自动容错和恢复功能，主从不可以自动切换
       2. 主机宕机，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低了系统的可用性
       3. 较难支持在线扩容
</code></pre>
<h1 id="Redis-哨兵"><a href="#Redis-哨兵" class="headerlink" title="Redis 哨兵"></a>Redis 哨兵</h1><pre><code>参考：
    1. [极客时间《Redis核心技术与实战》07 | 哨兵机制：主库挂了，如何不间断服务？](https://time.geekbang.org/column/article/274483)

哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。
哨兵与哨兵之间通过 pub/sub 建立联系。
哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。

监控：
    哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。
    如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。
    如果检测的是从库，那么，哨兵简单地把它标记为“主观下线”就行了，因为从库的下线影响一般不太大，集群的对外服务不会间断。
    但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，开启主从切换，因为主从切换开销很大，防止误判。
    只有 N/2 + 1 的哨兵实例，都判断主库已经“主观下线”了，主库才会被标记为“客观下线”。
选主：
    主库挂了以后，在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。
    然后，再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库。
    筛选过程除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。
    在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，就可以认为主从节点断连了。
    如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。
    打分过程分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。

    由哪个哨兵执行主从切换：
        任何一个实例只要自身判断主库“主观下线”后，就会给其他实例发送 is-master-down-by-addr 命令。
        接着，其他实例会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y 相当于赞成票，N 相当于反对票。
        一个哨兵获得了仲裁所需的赞成票数后，就可以标记主库为“客观下线”。
        这个所需的赞成票数是通过哨兵配置文件中的 quorum 配置项设定的。
        例如，现在有 5 个哨兵，quorum 配置的是 3，那么，一个哨兵需要 3 张赞成票，就可以标记主库为“客观下线”了。
        这 3 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。
        此时，这个哨兵就可以再给其他哨兵发送命令，表明希望由自己来执行主从切换，并让所有其他哨兵进行投票。
        这个投票过程称为“Leader 选举”。在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：
        第一，拿到半数以上的赞成票；
        第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。
        以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。
通知：
    在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。
    同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。
    每个哨兵实例会提供 pub/sub 机制，客户端可以从哨兵订阅消息。
    哨兵提供的消息订阅频道有很多，不同频道包含了主从库切换过程中的不同关键事件。
    客户端读取哨兵的配置文件后，可以获得哨兵的地址和端口，和哨兵建立网络连接。
    然后就可以在客户端执行订阅命令，来获取不同的事件消息。
</code></pre>
<p align='center'>
    <img data-src='/images/Redis-面试知识点总结（下）/Redis-哨兵.jpg'>
</p>

<pre><code>优缺点：
   优点：
       1. 主从模式的所有优点
       2. 主从可以自动切换，系统更健壮，可用性更高
   缺点：
       除了支持主从自动切换外的主从模式的所有缺点
</code></pre>
<h1 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h1><pre><code>参考：
    1. [【原创】为什么Redis集群有16384个槽](https://www.cnblogs.com/rjzheng/p/11430592.html)

从 Redis 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。
Redis Cluster 采用哈希槽（Hash Slot），来处理数据和实例之间的映射关系。

在 Redis Cluster 中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。

为什么采用 16384？

    1. 在 Redis 节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息。
       如果槽位为 65536，这块的大小是 65536÷8÷1024=8kb，发送心跳信息的消息头达 8k，发送的心跳包过于庞大。
       作者认为这样做不太值得。
    2. 并且一般情况下一个 Redis 集群不会有超过 1000 个 master 节点，所以 16384 的槽位是个比较合适的选择。

具体的映射过程分为两大步：
    1. 首先根据键值对的 key，按照 CRC16 算法计算一个 16bit 的值
    2. 然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽

哈希槽和实例的对应：
    部署 Redis Cluster 时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。
    也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数。
    当 16384 个 slot 都有节点在处理时，集群处于上线状态，反之只要有一个 slot 没有得到处理都会处理下线状态。

客户端如何定位数据？
    当客户端请求键值对时，会先计算键所对应的哈希槽，然后给相应的实例发送请求。
    在定位键值对数据时，它所处的哈希槽是可以通过计算得到的，这个计算可以在客户端发送请求时来执行。
    知道哈希槽后，客户端如何知道哈希槽分布在哪个实例上？
        Redis 实例会把自己的哈希槽信息发给和它相连接的其它实例，来完成哈希槽分配信息的扩散。
        当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了。
        客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。

Redis 集群间通信参用什么协议？
    gossip 协议通信

在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个：
    1. 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽
    2. 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍。
此时，实例可以通过相互传递消息，获得最新的哈希槽分配信息，但是，客户端是无法主动感知这些变化的。
这就会导致，它缓存的分配信息和最新的分配信息不一致。

Redis Cluster 采取重定向机制解决这个问题。
当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有对应的哈希槽，会给客户端返回 MOVED 响应结果，
结果中包含了新实例的访问地址。
如果此时，旧实例中的数据只有一部分迁移到了新实例，还有部分数据没有迁移，客户端会收到一条 ASK 报错信息。
代表这个哈希槽正在迁移。此时，客户端需要先给新实例发送一个 ASKING 命令（代表破例执行关于槽的命令一次）。
然后，客户端再向新实例发送 GET 命令，以读取数据。

故障发现和转移：
    如果节点 A 向节点 B 发送 ping 消息，节点 B 没有在规定的时间内响应 pong，那么节点 A 会标记节点 B 为 pfail 疑似下线状态，
    同时把 B 的状态通过消息的形式发送给其他节点，如果超过半数以上的节点都标记 B 为 pfail 状态，B 就会被标记为 fail 下线状态，
    此时将会发生故障转移。
    优先从复制数据较多的从节点选择一个成为主节点，并且接管下线节点的 slot，整个过程和哨兵非常类似，都是基于 Raft 协议做选举。
    但是如果下线的主节点没有从节点，整个集群还是处于不可用的状态。

Redis Cluster 并不能保证数据的强一致性，在实际中集群在特定的条件下可能会丢失写操作，原因是集群采用异步复制。
</code></pre>
<h1 id="Redis-中，sentinel-和-cluster-的区别和适用场景是什么？"><a href="#Redis-中，sentinel-和-cluster-的区别和适用场景是什么？" class="headerlink" title="Redis 中，sentinel 和 cluster 的区别和适用场景是什么？"></a>Redis 中，sentinel 和 cluster 的区别和适用场景是什么？</h1><pre><code>哨兵是解决了 Redis 的高可用，而 cluster 则是解决了 Redis 的高并发。
</code></pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis，面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis 面试知识点总结（中）</title>
    <url>/Redis-%E9%9D%A2%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%AD%EF%BC%89/</url>
    <content><![CDATA[<h1 id="热点-key-问题"><a href="#热点-key-问题" class="headerlink" title="热点 key 问题"></a>热点 key 问题</h1><pre><code>热点 key 问题就是，突然有几十万甚至更大的请求去访问 Redis 上的某个特定 key。
那么，这样会造成流量过于集中，达到 Redis 单实例瓶颈（一般是 10W OPS 级别），或者物理网卡上限，从而导致这台 Redis 的服务器 Hold 不住。

怎么发现热 key？
1. 凭借业务经验，进行预估哪些是热 key
2. 在客户端进行收集
3. 在 Proxy 层做收集
4. 用 Redis 自带命令
    4.1 monitor 命令，该命令可以实时抓取出 Redis 服务器接收到的命令，然后写代码统计出热 key 是啥。
        当然，也有现成的分析工具可以给你使用，比如 redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低 Redis 的性能。
    4.2 hotkeys 参数（必须配合 LFU），Redis 4.0.3 提供了 redis-cli 的热点 key 发现功能，执行 redis-cli 时加上 –hotkeys 选项即可。
        但是该参数在执行的时候，如果 key 比较多，执行起来比较慢。
5. 自己抓包评估，Redis 客户端使用 TCP 协议与服务端进行交互，通信协议采用的是 RESP。自己写程序监听端口，按照 RESP 协议解析数据，进行分析。
   缺点就是开发成本高，维护困难，有丢包可能性。

如何解决？
1. 设置二级缓存（推荐）
2. 利用分片算法的特性，对 key 进行打散处理
   hot key 之所以是 hot key，是因为它只有一个 key，落地到一个实例上。
   可以给 hot key 加上前缀或者后缀，把一个 hotkey 的数量经过分片分布到不同的实例上，将访问量均摊到所有实例。
</code></pre>
<span id="more"></span>

<h1 id="大-key-问题"><a href="#大-key-问题" class="headerlink" title="大 key 问题"></a>大 key 问题</h1><pre><code>由于 Redis 主线程为单线程模型，大 key 也会带来一些问题，如：
1. 集群模式在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 高。
2. 大 key 相关的删除或者自动过期时，会出现 qps 突降或者突升的情况，极端情况下，会造成主从复制异常，Redis 服务阻塞无法响应请求。

怎么发现大 key？
- Redis 4.0 之前的大 key 的发现与删除方法
  1. redis-rdb-tools 工具。Redis 实例上执行 bgsave，然后对 dump 出来的 rdb 文件进行分析，找到其中的大 key
  2. redis-cli --bigkeys 命令。可以找到某个实例 5 种数据类型（string、hash、list、set、zset）的最大 key
  3. 自定义的扫描脚本，以 Python 脚本居多，方法与 redis-cli --bigkeys 类似
- Redis 4.0 之后的大 key 的发现与删除方法
  Redis 4.0 引入了 memory usage 命令和 lazyfree 机制，不管是对大 key 的发现，还是解决大 key 删除或者过期造成的阻塞问题都有明显的提升。
  memory usage 可以用较小的代价去获取所有 key 的内存大小。

如何删除？
- Redis 4.0 之前的大 key 的发现与删除方法
  分解删除操作，把 大的 key 分解成小部分逐渐删除：
  list: 逐步 ltrim;
  zset: 逐步 zremrangebyscore
  hset: hscan，然后 hdel 删除
  set: sscan，然后 srem 删除
- Redis 4.0 之后的大 key 的发现与删除方法
  删除大key： lazyfree 机制
  unlink 命令，代替 DEL 命令，会把对应的大 key 放到 BIO_LAZY_FREE 后台线程任务队列，然后在后台异步删除。
</code></pre>
<h1 id="如何保证缓存与数据库双写时的数据一致性？"><a href="#如何保证缓存与数据库双写时的数据一致性？" class="headerlink" title="如何保证缓存与数据库双写时的数据一致性？"></a>如何保证缓存与数据库双写时的数据一致性？</h1><pre><code>参考：
    1. [再乱用缓存，cto可就发飙了！](https://juejin.cn/post/6958003634625839111)

对于缓存和数据库的操作，主要有以下两种方式。
1. 先删缓存，再更新数据库
先删除缓存，数据库还没有更新成功，此时如果读取缓存，缓存不存在，去数据库中读取到的是旧值，缓存不一致发生。
解决方案：
    延时双删
    延时双删的方案的思路是，为了避免更新数据库的时候，其他线程从缓存中读取不到数据，
    就在更新完数据库之后，再 sleep 一段时间，然后再次删除缓存。
    sleep 的时间要对业务读写缓存的时间做出评估，sleep 时间大于读写缓存的时间即可。
2. 先更新数据库，再删除缓存
更新数据库成功，如果删除缓存失败或者还没有来得及删除，那么，其他线程从缓存中读取到的就是旧值，还是会发生不一致。
解决方案：
    消息队列
    先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。
    缺点：引入消息中间件之后，问题更复杂，就算更新数据库和删除缓存都没有发生问题，
          消息的延迟也会带来短暂的不一致性，不过这个延迟相对来说还是可以接受的

    进阶版消息队列
    为了解决缓存一致性的问题单独引入一个消息队列，太复杂。
    其实，一般大公司本身都会有监听 binlog 消息的消息队列存在，主要是为了做一些核对的工作。
    这样，我们可以借助监听 binlog 的消息队列来做删除缓存的操作。
    这样做的好处是，不用你自己引入，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。
    当然，这样消息延迟的问题依然存在，但是相比单纯引入消息队列的做法更好一点。

其他解决方案：
    设置缓存过期时间
    每次放入缓存的时候，设置一个过期时间，比如 5 分钟，以后的操作只修改数据库，不操作缓存，等待缓存超时后从数据库重新读取。
    如果对于一致性要求不是很高的情况，可以采用这种方案。

为什么是删除，而不是更新缓存？
    当多个更新操作同时到来的时候，删除动作，产生的结果是确定的；而更新操作，则可能会产生不同的结果。
    以先更新数据库，再删除缓存来举例。
    两个请求 A 和 B，请求 B 在请求 A 之后，数据是最新的。
    由于缓存的存在，如果在保存时发生稍许的偏差，就会造成 A 的缓存值覆盖了 B 的值，那么数据库中的记录值，和缓存中的就产生了不一致，直到下一次数据变更。
</code></pre>
<h1 id="Redis-如何实现异步队列？"><a href="#Redis-如何实现异步队列？" class="headerlink" title="Redis 如何实现异步队列？"></a>Redis 如何实现异步队列？</h1><pre><code>一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。当 lpop 没有消息的时候，要适当 sleep 一会再重试。
如果不用 sleep 呢？list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。

能不能生产一次消费多次？
使用 pub/sub 主题订阅者模式，可以实现 1:N 的消息队列。
pub/sub 有什么缺点？
在消费者下线的情况下，生产的消息会丢失，改为使用专业的消息队列如 RocketMQ 等。
</code></pre>
<h1 id="Redis-如何实现延时队列？"><a href="#Redis-如何实现延时队列？" class="headerlink" title="Redis 如何实现延时队列？"></a>Redis 如何实现延时队列？</h1><pre><code>使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。
</code></pre>
<h1 id="Pipeline-有什么好处，为什么要用-Pipeline？"><a href="#Pipeline-有什么好处，为什么要用-Pipeline？" class="headerlink" title="Pipeline 有什么好处，为什么要用 Pipeline？"></a>Pipeline 有什么好处，为什么要用 Pipeline？</h1><pre><code>可以将多次 IO 往返的时间缩减为一次，并且减少 Redis 中的系统调用。
</code></pre>
<h1 id="Redis-如何实现分布式锁？"><a href="#Redis-如何实现分布式锁？" class="headerlink" title="Redis 如何实现分布式锁？"></a>Redis 如何实现分布式锁？</h1><pre><code>参考：
    1. [分布式锁的实现之 redis 篇](https://xiaomi-info.github.io/2019/12/17/redis-distributed-lock/)

Redis 锁主要利用 Redis 的 setnx 命令。
加锁命令：SETNX key value，当键不存在时，对键进行设置操作并返回成功，否则返回失败。KEY 是锁的唯一标识，一般按业务来决定命名。
解锁命令：DEL key，通过删除键值对释放锁，以便其他线程可以通过 SETNX 命令来获取锁。
锁超时：EXPIRE key timeout, 设置 key 的超时时间，以保证即使锁没有被显式释放，锁也可以在一定时间后自动释放，避免资源被永远锁住。
问题：
    1. SETNX 和 EXPIRE 非原子性
       使用 lua 脚本

    2. 锁误解除
       如果线程 A 成功获取到了锁，并且设置了过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；
       随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。

       通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。
       可生成一个 UUID 标识当前线程，使用 lua 脚本做验证标识和解锁操作

    3. 超时解锁导致并发
       如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，A 和 B 并发执行。

       A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题：
           1. 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
           2. 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

    4. 不可重入
       当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。
       如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。
       Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

       Redis Hash 数据结构来实现分布式锁，既存锁的标识也对重入次数进行计数

    5. 无法等待锁释放
       上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。

       1. 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。
          这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率。
       2. 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放时，发送锁释放消息。

    6. 集群
       主备切换、集群脑裂时会造成问题，使用 RedLock 算法
</code></pre>
<h1 id="Redis-分布式锁和-ZooKeeper-区别？"><a href="#Redis-分布式锁和-ZooKeeper-区别？" class="headerlink" title="Redis 分布式锁和 ZooKeeper 区别？"></a>Redis 分布式锁和 ZooKeeper 区别？</h1><pre><code>1. 实现难度上：Zookeeper &gt;= Redis
   对于直接操纵底层 API 来说，实现难度都是差不多的，都需要考虑很多边界场景。但由于 Zk 的 ZNode 天然具有锁的属性，很简单。
   Redis 需要考虑太多异常场景，比如锁超时、锁的高可用等，实现难度较大。

2. 服务端性能：Redis &gt; Zookeeper
   Zk 基于 Zab 协议，需要一半的节点 ACK，才算写入成功，吞吐量较低。如果频繁加锁、释放锁，服务端集群压力会很大。
   Redis 基于内存，只写 Master 就算成功，吞吐量高，Redis 服务器压力小。

3. 客户端性能：Zookeeper &gt; Redis
   Zk 由于有通知机制，获取锁的过程，添加一个监听器就可以了。避免了轮询，性能消耗较小。
   Redis 并没有通知机制，它只能使用类似 CAS 的轮询方式去争抢锁，较多空转，会对客户端造成压力。

4. 可靠性：Zookeeper &gt; Redis
   Zookeeper 就是为协调而生的，有严格的 Zab 协议控制数据的一致性，锁模型健壮。
   Redis 追求吞吐，可靠性上稍逊一筹。即使使用了 Redlock，也无法保证 100% 的健壮性，但一般的应用不会遇到极端场景，所以也被常用。
</code></pre>
<h1 id="什么是缓存击穿，怎么解决"><a href="#什么是缓存击穿，怎么解决" class="headerlink" title="什么是缓存击穿，怎么解决"></a>什么是缓存击穿，怎么解决</h1><pre><code>缓存击穿的概念就是单个 key 并发访问过高，过期时导致所有请求直接打到 DB 上.
这个和热 key 的问题比较类似，只是说的点在于过期导致请求全部打到 DB 上而已。

解决方案：
    1. 加锁更新，比如请求查询 A，发现缓存中没有，对 A 这个 key 加锁，
       同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。
    2. 将过期时间组合写在 value 中，通过异步的方式不断的刷新过期时间，防止此类现象。
</code></pre>
<h1 id="什么是缓存穿透，怎么解决"><a href="#什么是缓存穿透，怎么解决" class="headerlink" title="什么是缓存穿透，怎么解决"></a>什么是缓存穿透，怎么解决</h1><pre><code>参考：
    1. [利用 Redis 的 bitmap 实现简单的布隆过滤器](https://learnku.com/articles/46442)

缓存穿透是指查询不存在缓存中的数据，每次请求都会打到 DB，就像缓存不存在一样。

解决方案：
    针对这个问题，加一层布隆过滤器。
    布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的 K 个点，同时把他们置为 1。
    这样当用户再次来查询 A，而 A 在布隆过滤器值为 0，直接返回，就不会产生击穿请求打到 DB 了。
    使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置。
    理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。
    BloomFilter 用 Bitmap 实现，关于如何实现，可以参考 [1]
</code></pre>
<h1 id="什么是缓存雪崩，怎么解决"><a href="#什么是缓存雪崩，怎么解决" class="headerlink" title="什么是缓存雪崩，怎么解决"></a>什么是缓存雪崩，怎么解决</h1><pre><code>当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到 DB 上，这样可能导致整个系统的崩溃，称为雪崩。
雪崩和击穿、热 key 的问题不太一样，是指大规模的缓存都过期失效了。

解决方案：
    1. 针对不同 key 设置不同的过期时间，避免同时过期
    2. 限流，如果 Redis 宕机，可以限流，避免同时刻大量请求打崩 DB
    3. 二级缓存，同热 key 的方案
</code></pre>
<h1 id="Redis-并发竞争-key-问题如何解决？"><a href="#Redis-并发竞争-key-问题如何解决？" class="headerlink" title="Redis 并发竞争 key 问题如何解决？"></a>Redis 并发竞争 key 问题如何解决？</h1><pre><code>1. 分布式锁
2. 消息队列
</code></pre>
<h1 id="为什么-Redis-6-0-之后改用多线程？"><a href="#为什么-Redis-6-0-之后改用多线程？" class="headerlink" title="为什么 Redis 6.0 之后改用多线程？"></a>为什么 Redis 6.0 之后改用多线程？</h1><pre><code>Redis 使用多线程并非是完全摒弃单线程。
Redis 还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。
这样做的目的是因为 Redis 的性能瓶颈在于网络 IO 而非 CPU，使用多线程能提升 IO 读写的效率，从而整体提高 Redis 的性能。
</code></pre>
<h1 id="Redis-哪些地方用到了多线程，哪些地方是单线程？"><a href="#Redis-哪些地方用到了多线程，哪些地方是单线程？" class="headerlink" title="Redis 哪些地方用到了多线程，哪些地方是单线程？"></a>Redis 哪些地方用到了多线程，哪些地方是单线程？</h1><pre><code>1. 接收请求参数
2. 解析请求参数
3. 请求响应，即将结果返回给client
</code></pre>
<h1 id="Redis-的持久化方式"><a href="#Redis-的持久化方式" class="headerlink" title="Redis 的持久化方式"></a>Redis 的持久化方式</h1><pre><code>Redis 的持久化主要有两大机制，即 AOF(Append Only File) 日志和 RDB(Redis DataBase) 快照。

RDB 优缺点：
    优点：
        1. RDB 是一个紧凑压缩的二进制文件，代表 Redis 在某个时间点上的数据快照。非常适用于备份，全量复制等场景。
        2. 与 AOF 格式的文件相比，RDB 文件可以更快的重启。
        3. RDB 对灾难恢复非常有用，它是一个紧凑的文件，可以更快的传输到远程服务器进行 Redis 服务恢复
    缺点：
        1. RDB 方式数据没办法做到实时/秒级持久化，因为 bgsave 每次运行都要执行 fork 操作创建子进程，属于重量级操作，频繁执行成本过高。
           只能保存某个时间间隔的数据，如果在这个期间 Redis 故障了，就会丢失一段时间的数据。

AOF 优缺点：
    优点：
        1. AOF 持久化保存的数据更加完整，即使发生了意外情况，根据配置的保存策略只会丢失短时间内的数据（每次操作保存的话不会丢失）；
        2. AOF 持久化文件，非常容易理解和解析，它是把所有 Redis 键值操作命令，以文件的方式存入了磁盘。
           即使不小心使用 flushall 命令删除了所有信息，只要使用 AOF 文件，删除最后的 flushall 命令，重启 Redis 即可恢复之前误删的数据。
    缺点：
        1. 对于相同的数据集来说，AOF 文件要大于 RDB 文件
        2. 在 Redis 负载比较高的情况下，RDB 比 AOF 性能更好
        3. 重启恢复数据时不如 RDB 速度快

Redis 4.0 之后新增混合持久化方式，混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，
再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。
</code></pre>
<h1 id="Redis-AOF-日志原理"><a href="#Redis-AOF-日志原理" class="headerlink" title="Redis AOF 日志原理"></a>Redis AOF 日志原理</h1><pre><code>AOF 日志是写后日志，“写后”的意思是 Redis 是先执行命令，把数据写入内存，然后才记录日志。
为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。
所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令。
所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。
除此之外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作。

AOF 两个潜在的风险：
    1. 首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。
    2. 其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。
       这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而影响后续的操作。

三种写回策略：
    1. Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
    2. Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
    3. No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。
想要获得高性能，就选择 No 策略。
如果想要得到高可靠性保证，就选择 Always 策略
如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。

AOF 重写机制：
    AOF 文件过大之后再往里面追加命令记录的话，效率会变低，如果日志文件太大，发生宕机恢复过程也会非常缓慢，所以会有 AOF 重写机制
    AOF 重写机制指的是，对过大的 AOF 文件进行重写，以此来压缩AOF文件的大小。
    具体的实现是检查当前键值数据库中的键值对，记录键值对的最终状态，
    将对某个键值对重复操作后产生的多条操作记录压缩成一条，实现压缩 AOF 文件的大小。

AOF 重写过程：
    一个拷贝，两处日志
    总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；
    然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。
    而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。
</code></pre>
<h1 id="Redis-RDB-快照"><a href="#Redis-RDB-快照" class="headerlink" title="Redis RDB 快照"></a>Redis RDB 快照</h1><pre><code>Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave
    save：在主线程中执行，会导致阻塞；
    bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。

Redis 借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。
简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。
bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。
此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。
但是，如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。
然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。

如果频繁地执行全量快照，也会带来两方面的开销：
    1. 频繁将全量数据写入磁盘，会给磁盘带来很大压力，
       多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。
    2. fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。
</code></pre>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis，面试</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次查找 lua-resty-mysql 库 insert_id 的 bug</title>
    <url>/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%9F%A5%E6%89%BE-lua-resty-mysql-%E5%BA%93-insert-id-%E7%9A%84-bug/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>我们公司平时业务开发使用 OpenResty，也一直使用 lua-resty-mysql 库连接 Mysql。</p>
<p>有一个业务场景，MySQL 中表的主键是自增 id，业务需要在 insert 语句之后需要拿到此次插入的自增 id 值。<br>我们一直使用 lua-resty-mysql 库（Openresty 组件中的一个）中执行 insert 语句返回的 res.insert_id 作为这个值（<strong>这样可以一次请求就拿到这个值</strong>）。</p>
<p>但是最近开始这个值变成负数，导致业务出现很多错误，于是便开始排查为什么 res.insert_id 会返回负数。</p>
<h1 id="基本猜测"><a href="#基本猜测" class="headerlink" title="基本猜测"></a>基本猜测</h1><p>首先确定 res.insert_id 这个值是负数之后，第一反应想到的是会不会 MySQL 的主键超出类型范围，导致自增 id 变成负数，但是想到我们用的类型时 bigint，不太可能会超出范围，</p>
<span id="more"></span>

<p>而且查到<strong>自增 id 达到范围上限后，会出现插入报错，并不会出现负数</strong>，所以排除这种可能性。</p>
<p>之后便是去确认这个值是 MySQL 返回的还是我们用到的 lua-resty-mysql 库基于自己的规则生成的</p>
<ol>
<li>如果是 MySQL 返回，必然是哪里存在 bug，不是 MySQL 的 bug 导致某些行为返回的这个值是负数，就是 lua-resty-mysql 库解析 MySQL 返回值时出现问题。</li>
<li>如果是用到的 lua-resty-mysql 库基于自己的规则生成的，那就是我们使用的方式不对，毕竟 lua-resty-mysql 库的官方说明并没有提供这样的用法</li>
</ol>
<h1 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h1><p>随后开始查看 lua-resty-mysql 库的源码，看到了 res.insert_id 来源这里</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-insert_id-来源.png" height="300"/></div>
</center>

<p>因为之前对这份源码不太熟悉，所以第一反应是这个值是 lua-resty-mysql 基于自己的规则生成的（也就是上面的猜测 2），我们不能这样使用。</p>
<p>通过网上搜索我们这种业务场景，也发现别人都是建议使用 MySQL 自带的函数 LAST_INSERT_ID() 来获取这个值（<strong>这种方式和 MySQL 交互两次</strong>），<br>所以我想当然的以为是我们的使用方法错了（后来发现这种想法是错误的，并且网上很少有人提到 MySQL 在 insert 之后已经返回插入的自增 id 值了）。</p>
<p>后来仔细想想，如果是 lua-resty-mysql 基于自己的规则生成的这个值，那么为什么之前这个值都是正确的呢，lua-resty-mysql 又是怎么实现的呢？</p>
<p>基于这个想法，我又打开了源码，发现一开始的理解错了，这个值是基于 MySQL 的响应值解析而来的，上图中 _from_length_coded_bin(packet, pos) 这个函数的作用其实就是解析 MySQL 的二进制响应。</p>
<p>确定了这个问题之后，可以排除上面的猜测 2。<br>回到了猜测 1，但是这里面还漏掉一个原因。</p>
<p>MySQL 返回 insert_id 的这个值是不是代表我们需要的值？<br>或者说，如果 MySQL 官方没有明确说明这个值的含义，只是一个代表其他含义的值，那也不能说是哪里存在 bug，还是我们的使用方法错误，之前的正确只是巧合。</p>
<p>于是开始查阅 <a href="https://dev.mysql.com/doc/internals/en/packet-OK_Packet.html"> MySQL 关于插入后网络响应的官方说明 </a>，很快就找到了这个值。</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/MySQL-OK-包.png" height="300"/></div>
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/MySQL-int-lenenc.png" height="300"/></div>
</center>

<p>图里明确说明 last_insert_id（也就是我们上面提到的 insert_id）是最后的插入 id 值。</p>
<p>到此，基本可以确定猜测 1 是对的，<strong>MySQL 或者 lua-resty-mysql 库一定哪里存在 bug，导致没有按说明正确返回</strong>。</p>
<p>基于对 MySQL 的信任（毕竟用的人这么多，出错的概率很小，就算有错误一定有人提到过），先假设 lua-resty-mysql 存在问题。</p>
<p>于是我便开始查看 MySQL 的网络协议，需要如何正确解析，以及 lua-resty-mysql 库是否解析正确。</p>
<p><strong>注意这里需要一个背景知识，客户端在向 MySQL Server 发送 insert 语句后（相当于发送请求），MySQL Server 会返回 OK 的包（相当于服务器响应），里面会带有上图中的值</strong>。</p>
<p>可以看到 MySQL 的官方文档里面提到返回的 <a href="https://dev.mysql.com/doc/internals/en/integer.html#packet-Protocol::FixedLengthInteger">last_insert_id</a> 是一个 <strong>int<lenenc></strong> 类型。<br><strong>lenenc</strong> 在 MySQL 里代表变长，需要根据不同的情况分别解析。</p>
<p>对照 lua-resty-mysql 库的源码，发现解析的规则并没有错。</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-解析二进制源码.png" height="300"/></div>
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-解析二进制源码-2.png" height="300"/></div>
</center>

<p>排查到这里就陷入困难了，毕竟 lua-resty-mysql 库对网络协议的解析并没有错，难道是 MySQL 出现 bug 了？如果真是这样，排查起来就困难了，毕竟 MySQL 源码要复杂很多。</p>
<p><strong>其实这里可以用 tcpdump 等工具获取 MySQL 的响应值，分析网络协议中的这个值，来确定是到底是不是 MySQL 的问题，但是因为权限等原因太繁琐，所以不到万不得已就没有这样排查</strong>。</p>
<p>只能先去查一下 <a href="https://bugs.mysql.com/">MySQL 官方的 bug 平台</a>，发现并没有这样的 bug。</p>
<p>本着最后一丝希望，我在 <a href="https://github.com/openresty/lua-resty-mysql/issues">lua-resty-mysql 库的 issue 列表</a> 里搜索 insert_id，</p>
<p>终于发现有人遇到了同样的问题 <a href="https://github.com/openresty/lua-resty-mysql/pull/26">https://github.com/openresty/lua-resty-mysql/pull/26</a>（其实这一步应该最先进行，后面反思里会提到）。</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-insert_id-issue-old.png" height="300"/></div>
</center>

<p>里面提到因为 <strong>LuaJIT（可以理解为 lua-resty-mysql 库使用的语言） 位操作只支持 32 位有符号整数，所以 MySQL 的包并没有被正确解析</strong>，可以看到在当时还是 Open 的状态。</p>
<p>这也是为什么我查看源码并没有问题，但还是返回了负数的原因，因为我默认位运算没有 32 位整数的限制（毕竟还有这个限制的很少）。</p>
<p>下面章亦春大大（lua-resty-mysql 库，还有 Openresty 作者）回复，会在 5 月中旬假期回来查看，但那已经是 2015 了，到现在 2021 年 2 月末，过了将近 6 年，还是没有处理~~~</p>
<p>为了查看是否是这个原因，我也去查阅了 <a href="http://bitop.luajit.org/semantics.html">luajit 关于位运算的相关文档</a></p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/luajit-32-位整数.png" height="300"/></div>
</center>

<p>果然文档上写明 <strong>luajit 位运算会返回 32 位有符号整数范围的数字，OpenResty 使用的 luajit 虽然是自己的维护 luajit 分支，但是大部分都和原作者的相同，在这一点上也没有改动</strong>。</p>
<p>后来我自己手动模拟了一遍，发现确实当 Mysql 中自增 id 的值超过 32 位有符号整数上限的时候，这个问题是稳定复现的。</p>
<h1 id="最终结果"><a href="#最终结果" class="headerlink" title="最终结果"></a>最终结果</h1><p>因为之前有一次线上分享加到了章亦春大大的微信，所以干脆直接在微信上联系了章亦春大大。</p>
<p>说明了我的问题和排查到的结果之后，很快得到了回复，并且很快这个 issue 就得到了处理，不得不说，处理的速度还是很快的~</p>
<center class="half">
    <div style="display:inline-block;"><img data-src="/images/记一次查找-lua-resty-mysql-库-insert-id-的-bug/resty-mysql-insert_id-issue.png" height="300"/></div>
</center>

<p>至此，这个 bug 完美排查到并且解决了！</p>
<h1 id="事后反思"><a href="#事后反思" class="headerlink" title="事后反思"></a>事后反思</h1><p>虽然最后这个事情最终结束了，但是还是有一些值得思考的地方。</p>
<ol>
<li>首先，得到的最大的感触是不要重复造轮子，在遇到问题之后，最先确定是否是自己的原因（在这个例子中就是首先确定是否是使用方法错误），<br>下一步骤应该就是查找涉及的 issue 列表，而不是自己再从头排查，我在这个过程也花费了很多时间<br>（当然在这个例子里如果不知道背景知识，比如 MySQL 的 OK 响应包，直接查看 issue 列表也很难发现）；</li>
<li>当然排查的过程中收获也很多，比如对 lua-resty-mysql 库的源码掌握更清晰，对 client 和 MySQL server 之间的网络协议更加了解等等；</li>
<li>最后，对问题应该有刨根问底的精神，而不是网上简单的查不到就跳过，这种做事的方法也是很大的收获。</li>
</ol>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》1.安装后的目录结构以及 GitHub 项目概览</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B1.%E5%AE%89%E8%A3%85%E5%90%8E%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E4%BB%A5%E5%8F%8A%20GitHub%20%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%A7%88/</url>
    <content><![CDATA[<h1 id="OpenResty-的发展"><a href="#OpenResty-的发展" class="headerlink" title="OpenResty 的发展"></a>OpenResty 的发展</h1><p>OpenResty 并不像其他的开发语言一样从零开始搭建，而是基于成熟的开源组件——NGINX 和 LuaJIT。</p>
<p>OpenResty 诞生于 2007 年，不过，它的第一个版本并没有选择 Lua，而是用了 Perl，这跟作者章亦春的技术偏好有很大关系。</p>
<p>但 Perl 的性能远远不能达到要求，于是，在第二个版本中，Perl 就被 Lua 给替换了。</p>
<p>不过，在 OpenResty 官方的项目中，Perl 依然占据着重要的角色，OpenResty 工程化方面都是用 Perl 来构建，比如测试框架、Linter、CLI 等。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E7%9A%84%E4%B8%BB%E8%A6%81%E7%BB%84%E6%88%90.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 的主要组成</div>
</center>

<span id="more"></span>

<h1 id="OpenResty-安装后的目录结构"><a href="#OpenResty-安装后的目录结构" class="headerlink" title="OpenResty 安装后的目录结构"></a>OpenResty 安装后的目录结构</h1><p>安装后主要包含了 bin、luajit、lualib、nginx、pod 这几个子目录</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E5%AE%89%E8%A3%85%E5%90%8E%E7%9A%84%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 安装后的目录结构</div>
</center>

<h2 id="bin"><a href="#bin" class="headerlink" title="bin"></a>bin</h2><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/bin%20%E7%9B%AE%E5%BD%95.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">bin 目录</div>
</center>

<p>openresty，它其实是 nginx 的一个软链接。</p>
<p>opm 是包管理工具，可以通过它来管理各类第三方包。</p>
<p>resty 是 OpenResty CLI，安装完 OpenResty 后，会默认安装。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/resty%20%E7%A4%BA%E4%BE%8B.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">resty 示例</div>
</center>

<p>restydoc 可以查看帮助文档。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/restydoc%20%E7%A4%BA%E4%BE%8B.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">restydoc 示例</div>
</center>

<p>目录里面其他的一些工具，和 resty 一样，都是 Perl 脚本。</p>
<h2 id="pod"><a href="#pod" class="headerlink" title="pod"></a>pod</h2><p>pod 是 Perl 里面的一种标记语言，用于给 Perl 的模块编写文档。<br>pod 目录中存放的就是 OpenResty、 NGINX、lua-resty-*、LuaJIT 的文档， 和刚才提到的 restydoc 联系在一起。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/pod%20%E7%9B%AE%E5%BD%95.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">pod 目录</div>
</center>

<h2 id="nginx-和-luajit"><a href="#nginx-和-luajit" class="headerlink" title="nginx 和 luajit"></a>nginx 和 luajit</h2><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/nginx%20%E5%92%8C%20luajit%20%E7%9B%AE%E5%BD%95.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">nginx 和 luajit 目录</div>
</center>

<br/>
主要存放 NGINX 和 LuaJIT 的可执行文件和依赖，是 OpenResty 的基石。

<p>早期的 OpenResty 同时带有 Lua 和 LuaJIT，可以通过编译选项，来决定使用 Lua 还是 LuaJIT。</p>
<p>不过到了现在，Lua 逐渐被淘汰，就只支持更高性能的 LuaJIT 了。</p>
<h2 id="lualib"><a href="#lualib" class="headerlink" title="lualib"></a>lualib</h2><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/lualib%20%E7%9B%AE%E5%BD%95.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">lualib 目录</div>
</center>

<br/>
里面存放的是 OpenResty 中使用到的 Lua 库，主要分为 ngx 和 resty 两个子目录。

<p>前者存放的是 lua-resty-core 这个官方项目中的 Lua 代码，里面都是基于 FFI 重新实现的 OpenResty API。</p>
<p>resty 目录中存放的则是各种 lua-resty-* 项目包含的 Lua 代码。</p>
<h1 id="OpenResty-GitHub-项目概览"><a href="#OpenResty-GitHub-项目概览" class="headerlink" title="OpenResty GitHub 项目概览"></a>OpenResty GitHub 项目概览</h1><p>OpenResty 在 GitHub 的项目主页：<a href="https://github.com/openresty/">openresty</a></p>
<p>大概分为以下 7 类：</p>
<h2 id="NGINX-C-模块"><a href="#NGINX-C-模块" class="headerlink" title="NGINX C 模块"></a>NGINX C 模块</h2><p>OpenResty 的项目命名都是有规范的，以 *-nginx-module命名的就是 NGINX 的 C 模块。<br>openresty -V 中，可以看到这些 C 模块</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/openresty%20-V.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">openresty -V</div>
</center>

<br/>
--add-module=后面跟着的，就是 OpenResty 的 C 模块。其中，最核心的就是 lua-nginx-module 和 stream-lua-nginx-module，前者用来处理七层流量，后者用来处理四层流量。

<p>这些 C 模块中，有些是需要特别注意的，虽然默认编译进入了 OpenResty，但并不推荐使用。<br>比如 redis2-nginx-module、redis-nginx-module 和 memc-nginx-module，它们是用来和 redis 以及 memcached 交互使用的。<br>这些 C 库是 OpenResty 早期推荐使用的，但在 cosocket 功能加入之后，它们都已经被 lua-resty-redis 和 lua-resty-memcached 替代，处于疏于维护的状态。<br>OpenResty 后面也不会开发更多的 NGINX C 库，而是专注在基于 cosocket 的 Lua 库上，后者才是未来。</p>
<h2 id="lua-resty-周边库"><a href="#lua-resty-周边库" class="headerlink" title="lua-resty- 周边库"></a>lua-resty- 周边库</h2><p>官方自带<br>在 OpenResty 世界中，如果使用 cosocket 实现了一个包，那么就要使用 lua-resty- 这个前缀，算是一个不成文的规定。</p>
<p>除了官方自带的之外，还有更多的第三方库。</p>
<h2 id="自己维护的-LuaJIT-分支"><a href="#自己维护的-LuaJIT-分支" class="headerlink" title="自己维护的 LuaJIT 分支"></a>自己维护的 LuaJIT 分支</h2><p>OpenResty 除了维护自己的 OpenSSL patch 外，还维护了自己的 LuaJIT 分支。<br>在 2015 年，LuaJIT 的作者 Mike Pall 宣布退休，寻找新的 LuaJIT 维护者，但 Mike 并没有找到合适的维护者，他现在主要是做 bugfix 的维护工作，新功能的开发也已经暂停，所以 OpenResty 维护着自己的 LuaJIT 分支。<br>相对于 Lua，LuaJIT 增加了不少独有的函数，这些函数非常重要</p>
<h2 id="测试框架"><a href="#测试框架" class="headerlink" title="测试框架"></a>测试框架</h2><p>OpenResty 的测试框架是test-nginx，同样也是用 Perl 语言来开发的，从名字上就能看出来，它是专门用来测试 NGINX 相关的项目。<br>OpenResty 官方的所有 C 模块和 lua-resty 库的测试案例，都是由 test-nginx 驱动的。</p>
<h2 id="调试工具链"><a href="#调试工具链" class="headerlink" title="调试工具链"></a>调试工具链</h2><p>OpenResty 项目在如何科学和动态地调试代码上，花费了大量的精力。</p>
<p>OpenResty 的作者章亦春专门写了一篇文章，来介绍动态追踪技术。<br>强烈推荐，看完也有助于理解对应的工具链以及系统性能优化 <a href="https://blog.openresty.com.cn/cn/dynamic-tracing/#fnref2">动态追踪技术漫谈</a>。</p>
<p>openresty-systemtap-toolkit 和 stapxx 这两个 OpenResty 的项目，都基于 systemtap 这个动态调试和追踪工具。</p>
<p>使用 systemtap 最大的优势，便是实现活体分析，同时对目标程序完全无侵入。<br>打个比方，systemtap，就像是我们去医院照了个 CT，无痛无感知。更棒的是，systemtap 可以生成直观的火焰图来做性能分析，这里先放一个火焰图，直观上有个感性的认识。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/%E7%81%AB%E7%84%B0%E5%9B%BE.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">火焰图</div>
</center>

<h2 id="打包相关"><a href="#打包相关" class="headerlink" title="打包相关"></a>打包相关</h2><p>OpenResty 在不同发行操作系统（比如 CentOS、Ubuntu、MacOS 等）版本中的打包脚本</p>
<h2 id="工程化工具"><a href="#工程化工具" class="headerlink" title="工程化工具"></a>工程化工具</h2><p>比如 openresty-devel-utils 就是开发 OpenResty 和 NGINX 的工具集。它们也都使用 Perl 开发，其中大部分的工具都是没有文档的。<br>但对于 OpenResty 的开发者来说，这些工具又是非常有用的。</p>
<p>lj-releng 是一个简单有效的 LuaJIT 代码检测工具，类似 luacheck，可以找出全局变量等潜在的问题。</p>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》3.OpenResty 高性能的原因</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B3.OpenResty%20%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E5%8E%9F%E5%9B%A0/</url>
    <content><![CDATA[<h1 id="OpenResty-高性能的原因"><a href="#OpenResty-高性能的原因" class="headerlink" title="OpenResty 高性能的原因"></a>OpenResty 高性能的原因</h1><h2 id="运行在-Nginx-整体架构之上"><a href="#运行在-Nginx-整体架构之上" class="headerlink" title="运行在 Nginx 整体架构之上"></a>运行在 Nginx 整体架构之上</h2><p>OpenResty 的 master 和 worker 进程中，都包含一个 LuaJIT VM。在同一个进程内的所有协程，都会共享这个 VM，并在这个 VM 中运行 Lua 代码。</p>
<p>而在同一个时间点上，每个 worker 进程只能处理一个用户的请求，也就是只有一个协程在运行。</p>
<p>NGINX 实际上是通过 epoll 的事件驱动，来减少等待和空转，才尽可能地让 CPU 资源都用于处理用户的请求。<br>毕竟，只有单个的请求被足够快地处理完，整体才能达到高性能的目的。<br>如果采用的是多线程模式，让一个请求对应一个线程，那么在 C10K 的情况下，资源很容易就会被耗尽的。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E5%92%8C%20LuaJit%20%E6%9E%B6%E6%9E%84%E5%9B%BE.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 和 LuaJit 架构图</div>
</center>

<span id="more"></span>

<h2 id="cosocket"><a href="#cosocket" class="headerlink" title="cosocket"></a>cosocket</h2><p>是 OpenResty 的核心和精髓。</p>
<p>在早期的 OpenResty 版本中，如果想要去与 Redis、memcached 这些服务交互的话，需要使用 redis2-nginx-module、redis-nginx-module 和 memc-nginx-module这些 C 模块。</p>
<p>这些模块至今仍然在 OpenResty 的发行包中。不过，cosocket 功能加入以后，它们都已经被 lua-resty-redis 和 lua-resty-memcached 替代，基本上没人再去使用 C 模块连接外部服务了。</p>
<p>实际上，cosocket 是 OpenResty 中的专有名词，是把协程和网络套接字的英文拼在一起形成的，即 cosocket = coroutine + socket。</p>
<p>cosocket 是各种 lua-resty-* 非阻塞库的基础，没有 cosocket，开发者就无法用 Lua 来快速连接各种外部的网络服务。</p>
<p>cosocket 不仅需要 Lua 协程特性的支持，也需要 Nginx 中非常重要的事件机制的支持，这两者结合在一起，最终实现了非阻塞网络 I/O。</p>
<p>如果我们在 OpenResty 中调用一个 cosocket 相关函数，内部实现便是下面这张图的样子：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/cosocket%20%E5%87%BD%E6%95%B0%E6%B5%81%E7%A8%8B.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">cosocket 函数流程</div>
</center>

<br/>
遇到网络 I/O 时，它会交出控制权（yield），把网络事件注册到 Nginx 监听列表中，并把权限交给 Nginx；当有 Nginx 事件达到触发条件时，便唤醒对应的协程继续处理（resume）。

<h3 id="cosocket-API-和指令简介"><a href="#cosocket-API-和指令简介" class="headerlink" title="cosocket API 和指令简介"></a>cosocket API 和指令简介</h3><ul>
<li>创建对象：ngx.socket.tcp。</li>
<li>设置超时：tcpsock:settimeout 和 tcpsock:settimeouts。</li>
<li>建立连接：tcpsock:connect。</li>
<li>发送数据：tcpsock:send。</li>
<li>接受数据：tcpsock:receive、tcpsock:receiveany 和 tcpsock:receiveuntil。</li>
<li>连接池：tcpsock:setkeepalive。</li>
<li>关闭连接：tcpsock:close。</li>
</ul>
<p>这些 API 可以使用的上下文：<br/><br>rewrite_by_lua*, access_by_lua*, content_by_lua*, ngx.timer.<em>, ssl_certificate_by_lua</em>, ssl_session_fetch_by_lua*_<br>在某些阶段是不能使用的，比如 init_by_lua，log_by_lua*，参考 <a href="https://github.com/openresty/lua-nginx-module#cosockets-not-available-everywhere">Cosockets Not Available Everywhere</a></p>
<h2 id="LuaJit"><a href="#LuaJit" class="headerlink" title="LuaJit"></a>LuaJit</h2><p>通过 tracing 对热代码进行编译。</p>
<h3 id="LuaJIT-在-OpenResty-整体架构中的位置"><a href="#LuaJIT-在-OpenResty-整体架构中的位置" class="headerlink" title="LuaJIT 在 OpenResty 整体架构中的位置"></a>LuaJIT 在 OpenResty 整体架构中的位置</h3><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/luajit%20%E5%9C%A8%20openresty%20%E6%9E%B6%E6%9E%84%E4%B8%AD%E4%BD%8D%E7%BD%AE.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">LuaJIT 在 OpenResty 整体架构中的位置</div>
</center>
<br/>

<p>OpenResty 的 worker 进程都是 fork master 进程而得到的，master 进程中的 LuaJIT 虚拟机也会一起 fork 过来。</p>
<p>在同一个 worker 内的所有协程，都会共享这个 LuaJIT 虚拟机，Lua 代码的执行也是在这个虚拟机中完成的。</p>
<h3 id="LuaJIT-vs-Lua"><a href="#LuaJIT-vs-Lua" class="headerlink" title="LuaJIT vs Lua"></a>LuaJIT vs Lua</h3><p>标准 Lua 和 LuaJIT 是两回事儿，LuaJIT 只是兼容了 Lua 5.1 的语法。</p>
<p>在 OpenResty 中，可以用 Lua C API 来调用 C 函数，还可以在 LuaJIT 中使用 FFI。</p>
<h4 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h4><p>其实标准 Lua 出于性能考虑，也内置了虚拟机 （Lua VM），所以 Lua 代码并不是直接被解释执行的，而是先由 Lua 编译器编译为字节码（Byte Code），然后再由 Lua 虚拟机执行。</p>
<p>而 LuaJIT 的运行时环境，除了一个汇编实现的 Lua 解释器外，还有一个可以直接生成机器代码的 JIT 编译器。</p>
<p>开始的时候，LuaJIT 和标准 Lua 一样，Lua 代码被编译为字节码，字节码被 LuaJIT 的解释器解释执行。<br>但不同的是，LuaJIT 的解释器会在执行字节码的同时，记录一些运行时的统计信息，当这些次数超过某个随机的阈值时，便认为对应的 Lua 函数入口或者对应的 Lua 循环足够热，这时便会触发 JIT 编译器开始工作。<br>编译的过程，是把 LuaJIT 字节码先转换成 LuaJIT 自己定义的中间码（IR），然后再生成针对目标体系结构的机器码。</p>
<p>所以，所谓 LuaJIT 的性能优化，本质上就是让尽可能多的 Lua 代码可以被 JIT 编译器生成机器码，而不是回退到 Lua 解释器的解释执行模式。</p>
<h4 id="FFI"><a href="#FFI" class="headerlink" title="FFI"></a>FFI</h4><p>除了兼容 Lua 5.1 的语法并支持 JIT 外，LuaJIT 还紧密结合了 FFI（Foreign Function Interface），可以直接在 Lua 代码中调用外部的 C 函数和使用 C 的数据结构。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/test_ffi.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">test_ffi</div>
</center>

<br/>
类似的，我们可以用 FFI 来调用 NGINX、OpenSSL 的 C 函数，来完成更多的功能。

<p>实际上，FFI 方式比传统的 Lua/C API 方式的性能更优，这也是 lua-resty-core 项目（后面会介绍）存在的意义。</p>
<h4 id="JIT-为什么不是全程编译？"><a href="#JIT-为什么不是全程编译？" class="headerlink" title="JIT 为什么不是全程编译？"></a>JIT 为什么不是全程编译？</h4><p>既然编译过后效率更高，为什么不采用全程编译，而是只针对热代码编译？</p>
<ol>
<li><p>时间</p>
<p> 如果是少量运行，得不偿失</p>
</li>
<li><p>空间</p>
<p> 编译后占用的内存会变大</p>
</li>
<li><p>JIT 编译优化需要运行的信息</p>
<p> 并不是所有的编译执行都比解释执行效率高，给的运行时信息越多，效果越好</p>
</li>
</ol>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》2.一次完整的请求流程是怎样的</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B2.%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AF%B7%E6%B1%82%E6%B5%81%E7%A8%8B%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84/</url>
    <content><![CDATA[<h1 id="OpenResty-一次完整的请求流程是怎样的"><a href="#OpenResty-一次完整的请求流程是怎样的" class="headerlink" title="OpenResty 一次完整的请求流程是怎样的"></a>OpenResty 一次完整的请求流程是怎样的</h1><p>OpenResty 使用 Nginx 作为底层的 Web 服务器。</p>
<h2 id="Nginx-是如何接收到请求的"><a href="#Nginx-是如何接收到请求的" class="headerlink" title="Nginx 是如何接收到请求的"></a>Nginx 是如何接收到请求的</h2><h3 id="Nginx-整体架构"><a href="#Nginx-整体架构" class="headerlink" title="Nginx 整体架构"></a>Nginx 整体架构</h3><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/Nginx%20%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E5%9B%BE.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Nginx 整体架构图</div>
</center>

<br/>
Nginx 里有一个 master 进程和多个 worker 进程。

<span id="more"></span>

<p>master 进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程及非停升级。<br>worker 进程负责处理网络请求与响应。</p>
<p>master 进程主要用来管 理worker 进程，具体包括如下 4 个主要功能：</p>
<ul>
<li>接收来自外界的信号。</li>
<li>向各 worker 进程发送信号。</li>
<li>监控 woker 进程的运行状态。</li>
<li>当 woker 进程退出后（异常情况下），会自动重新启动新的 woker 进程。</li>
</ul>
<p>woker 进程主要用来处理基本的网络事件：</p>
<ul>
<li>多个 worker 进程之间是对等且相互独立的，他们同等竞争来自客户端的请求。</li>
<li>每个 worker 进程是单线程。</li>
<li>一个请求，只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。</li>
</ul>
<h3 id="Nginx-模块化设计"><a href="#Nginx-模块化设计" class="headerlink" title="Nginx 模块化设计"></a>Nginx 模块化设计</h3><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/Nginx%20%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%E5%8F%8A%E5%85%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Nginx 常用模块及其之间的关系</div>
</center>

<h3 id="Nginx-执行阶段"><a href="#Nginx-执行阶段" class="headerlink" title="Nginx 执行阶段"></a>Nginx 执行阶段</h3><p>下面是详细的 11 个阶段，每个阶段都可能对应着一个甚至多个 HTTP 模块：</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/Nginx%2011%20%E4%B8%AA%E6%89%A7%E8%A1%8C%E9%98%B6%E6%AE%B5%E8%A1%A8%E6%A0%BC.jpg">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Nginx 11 个执行阶段表格</div>
</center>

<br/>
1. POST_READ：在 read 完请求的头部之后，在没有对头部做任何处理之前，想要获取到一些原始的值，就应该在这个阶段进行处理。这里面会涉及到一个 realip 模块。
2. SERVER_REWRITE：和下面的 REWRITE 阶段一样，都只有一个模块叫 rewrite 模块，一般没有第三方模块会处理这个阶段。
3. FIND_CONFIG：做 location 的匹配，暂时没有模块会用到。
4. REWRITE：对 URL 做一些处理。
5. POST_WRITE：处于 REWRITE 之后，也是暂时没有模块会在这个阶段出现。
接下来是确认用户访问权限的三个模块：

<p>接下来是确认用户访问权限的三个模块：</p>
<ol>
<li>PREACCESS：是在 ACCESS 之前要做一些工作，例如并发连接和 QPS 需要进行限制，涉及到两个模块：limt_conn 和 limit_req</li>
<li>ACCESS：核心要解决的是用户能不能访问的问题，例如 auth_basic 是用户名和密码，access 是用户访问 IP，auth_request 根据第三方服务返回是否可以去访问。</li>
<li>POST_ACCESS：是在 ACCESS 之后会做一些事情，同样暂时没有模块会用到。</li>
</ol>
<p>最后的三个阶段处理响应和日志：</p>
<ol>
<li>PRECONTENT：在处理 CONTENT 之前会做一些事情，例如会把子请求发送给第三方的服务去处理，try_files 模块也是在这个阶段中。</li>
<li>CONTENT：这个阶段涉及到的模块就非常多了，例如 index, autoindex, concat 等都是在这个阶段生效的。</li>
<li>LOG：记录日志 access_log 模块。</li>
</ol>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/Nginx%2011%20%E4%B8%AA%E6%89%A7%E8%A1%8C%E9%98%B6%E6%AE%B5%E7%A4%BA%E4%BE%8B.jpg">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Nginx 11 个执行阶段示例</div>
</center>

<h2 id="OpenResty-的运行机制"><a href="#OpenResty-的运行机制" class="headerlink" title="OpenResty 的运行机制"></a>OpenResty 的运行机制</h2><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 的运行机制</div>
</center>

<h2 id="OpenResty-执行阶段"><a href="#OpenResty-执行阶段" class="headerlink" title="OpenResty 执行阶段"></a>OpenResty 执行阶段</h2><p>lua-nginx-module 以第三方模块的方式嵌入到 Nginx 的各个执行阶段里。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E6%89%A7%E8%A1%8C%E9%98%B6%E6%AE%B5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 执行阶段</div>
</center>

<br/>

<p>常用的阶段有：</p>
<ul>
<li>init_by_lua*: master 启动，里面的变量会复制到各个 worker</li>
<li>init_worker_by_lua*: worker 启动</li>
<li>set_by_lua*: 流程分支处理判断变量初始化</li>
<li>rewrite_by_lua*: 转发、重定向、缓存等功能(例如特定请求代理到外网)</li>
<li>access_by_lua*: IP 准入、接口权限等情况集中处理(例如配合 iptable 完成简单防火墙)</li>
<li>content_by_lua*: 内容生成</li>
<li>header_filter_by_lua*: 响应头部过滤处理(例如添加头部信息)</li>
<li>body_filter_by_lua*: 响应体过滤处理(例如完成应答内容统一成大写)</li>
<li>log_by_lua*: 会话完成后本地异步完成日志记录(日志可以记录在本地，还可以同步到其他机器)</li>
</ul>
<h3 id="OpenResty-执行阶段和-Nginx-的对照"><a href="#OpenResty-执行阶段和-Nginx-的对照" class="headerlink" title="OpenResty 执行阶段和 Nginx 的对照"></a>OpenResty 执行阶段和 Nginx 的对照</h3><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E6%89%A7%E8%A1%8C%E9%98%B6%E6%AE%B5%E5%AF%B9%E7%85%A7.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 执行阶段对照</div>
</center>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》4.一些特性和用法</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B4.%E4%B8%80%E4%BA%9B%E7%89%B9%E6%80%A7%E5%92%8C%E7%94%A8%E6%B3%95/</url>
    <content><![CDATA[<h1 id="一些特性和用法"><a href="#一些特性和用法" class="headerlink" title="一些特性和用法"></a>一些特性和用法</h1><h2 id="同步非阻塞"><a href="#同步非阻塞" class="headerlink" title="同步非阻塞"></a>同步非阻塞</h2><center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/%E9%9D%9E%E9%98%BB%E5%A1%9E%E8%B0%83%E7%94%A8.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">非阻塞调用</div>
</center>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/%E9%9D%9E%E9%98%BB%E5%A1%9E%E8%B0%83%E7%94%A8%E4%B8%8B%E7%9A%84%E5%90%8C%E6%AD%A5%E5%92%8C%E5%BC%82%E6%AD%A5.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">非阻塞调用下的同步和异步</div>
</center>

<br/>
除了 ngx.timer 等少数异步操作外，使用 OpenResty 只需要编写同步的代码就可以，而不需要类似 Nginx 源码那样编写很多异步的代码。

<span id="more"></span>

<h2 id="文档格式一致"><a href="#文档格式一致" class="headerlink" title="文档格式一致"></a>文档格式一致</h2><p>/t 目录，它里面就是所有的测试案例</p>
<center class="half">
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/resty%20%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%841.png" width="400"/>
    <img data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/resty%20%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%842.png" width="400"/>
</center>

<h2 id="shared-dict"><a href="#shared-dict" class="headerlink" title="shared dict"></a>shared dict</h2><p>shared dict 可以完成 worker 间的数据共享，并借此实现 worker 之间的通信</p>
<h2 id="lua-nginx-module-vs-lua-resty-core"><a href="#lua-nginx-module-vs-lua-resty-core" class="headerlink" title="lua-nginx-module vs lua-resty-core"></a>lua-nginx-module vs lua-resty-core</h2><p>对于 OpenResty 的实现，可能大部分的认识都是 OpenResty 是基于 lua-nginx-module 实现的，而不知道 lua-resty-core 这个项目，实际上，官方后续的计划便是把越来越多的功能采用 lua-resty-core 重新实现。</p>
<p>在核心的 lua-nginx-module 中，调用 C 函数的 API，都是使用 Lua C API 来完成的；</p>
<p>而在 lua-resty-core 中，则是把 lua-nginx-module 已有的部分 API，使用 FFI 的模式重新实现了一遍。</p>
<p>如果比较关注 <a href="http://openresty.org/en/changelog-1019003.html">OpenResty 新版特性</a> 的话，可以发现一些关于 lua-resty-core 的说明，比如基于 lua-resty-core 实现了更多的功能等等，都是基于这个目的，至于原因下面会讲到。</p>
<p>需要澄清下，lua-nginx-module 提供的 API，是通过 C 实现，并通过 Lua CFunction 暴露出来的。</p>
<p>而 lua-resty-core 提供的 API，也不是表面看上去那样用 Lua 实现的，是通过在 lua-nginx-module 里面的以 <em><em>lua_ffi</em></em> 形式命名的 C 函数实现的，并在 lua-resty-core 里面通过 LuaJIT FFI 暴露出来的。</p>
<p>所以其实两者都是 C 实现。两者的比较，应该是 Lua CFunction 和 LuaJIT FFI 的比较。</p>
<h3 id="Lua-CFunction"><a href="#Lua-CFunction" class="headerlink" title="Lua CFunction"></a>Lua CFunction</h3><p>以 ngx.base64_decode 举例，lua-nginx-module 实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">static int</span><br><span class="line"> ngx_http_lua_ngx_decode_base64(lua_State *L)</span><br><span class="line"> &#123;</span><br><span class="line">     ngx_str_t p, src;</span><br><span class="line"> </span><br><span class="line">    src.data &#x3D; (u_char *) luaL_checklstring(L, 1, &amp;src.len);</span><br><span class="line"> </span><br><span class="line">     p.len &#x3D; ngx_base64_decoded_length(src.len);</span><br><span class="line"> </span><br><span class="line">     p.data &#x3D; lua_newuserdata(L, p.len);</span><br><span class="line"> </span><br><span class="line">     if (ngx_decode_base64(&amp;p, &amp;src) &#x3D;&#x3D; NGX_OK) &#123;</span><br><span class="line">         lua_pushlstring(L, (char *) p.data, p.len);</span><br><span class="line"> </span><br><span class="line">     &#125; else &#123;</span><br><span class="line">         lua_pushnil(L);</span><br><span class="line">     &#125;</span><br><span class="line"> </span><br><span class="line">     return 1;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>用 C 编写的函数，无法把返回值传给 Lua 代码，而是需要通过栈，来传递 Lua 和 C 之间的调用参数和返回值。</p>
<p>同时，这些代码也不能被 JIT 跟踪到，所以对于 LuaJIT 而言，这些操作是处于黑盒中的，没法进行优化。</p>
<h3 id="LuaJIT-FFI"><a href="#LuaJIT-FFI" class="headerlink" title="LuaJIT FFI"></a>LuaJIT FFI</h3><p>FFI 的交互部分是用 Lua 实现的，这部分代码可以被 JIT 跟踪到，并进行优化；<br>当然，代码也会更加简洁易懂。</p>
<p>以 ngx.base64_decode 举例，lua-resty-core 实现 <a href="https://github.com/openresty/lua-resty-core/blob/master/lib/resty/core/base64.lua#L60">https://github.com/openresty/lua-resty-core/blob/master/lib/resty/core/base64.lua#L60</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ngx.decode_base64 &#x3D; function (s)</span><br><span class="line">     local slen &#x3D; #s</span><br><span class="line">     local dlen &#x3D; base64_decoded_length(slen)</span><br><span class="line">     </span><br><span class="line">     local dst &#x3D; get_string_buf(dlen)</span><br><span class="line">     local pdlen &#x3D; get_size_ptr()</span><br><span class="line">     local ok &#x3D; C.ngx_http_lua_ffi_decode_base64(s, slen, dst, pdlen)</span><br><span class="line">     if ok &#x3D;&#x3D; 0 then</span><br><span class="line">         return nil</span><br><span class="line">     end</span><br><span class="line">     return ffi_string(dst, pdlen[0])</span><br><span class="line"> end</span><br></pre></td></tr></table></figure>

<h3 id="值得说明的几个点"><a href="#值得说明的几个点" class="headerlink" title="值得说明的几个点"></a>值得说明的几个点</h3><ul>
<li><p>FFI + JIT 在跟 C 领域频繁数据交互的领域才明显，例如：</p>
<ul>
<li>ngx.md5 相差不大</li>
<li>ngx.ctx, ngx.re.find, ngx.time 效果相差几十倍</li>
</ul>
</li>
<li><p>解释模式下 LuaJIT 的 FFI 操作很慢，比编译模式下慢十倍。<br>调用 Lua CFunction 会迫使 LuaJIT 退回到解释模式，而通过 FFI 调用 C 函数则不会。</p>
</li>
<li><p>除了不会打断 tracing，FFI 实现的版本还有另一个优势：LuaJIT 能够在编译时优化 FFI 实现代码。</p>
</li>
<li><p>在 OpenResty 2019 年 5 月份发布的 1.15.8.1 版本前，lua-resty-core 默认是不开启的，而这不仅会带来性能损失，更严重的是会造成潜在的 bug。</p>
<p>强烈推荐还在使用历史版本的用户，都手动开启 lua-resty-core。只需要在 init_by_lua 阶段，增加一行代码就可以了：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">require &quot;resty.core&quot;</span><br></pre></td></tr></table></figure>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.15.8.1 版本中，增加了 lua_load_resty_core 指令，可以选择开启或关闭加载 lua-resty-core（默认开启）。<br/><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.17.8.1 版本后，lua_load_resty_core 指令被废除，lua-resty-core 是强制加载的，这对于开源项目来说是一个很好的决定，在没有什么理由选择更糟糕的实现的时候，强制帮助用户选择好，防止给不熟悉的用户更多的疑惑性选择。</p>
<ul>
<li><p>OpenResty 中的函数都是有命名规范的，可以通过命名推测出它的用处。</p>
<p>  比如：<br><br>  &ensp;&ensp;&ensp;&ensp;ngx_http_lua_ffi_ ，是用 FFI 来处理 NGINX HTTP 请求的 Lua 函数；<br><br>  &ensp;&ensp;&ensp;&ensp;ngx_http_lua_ngx_ ，是用 Cfunction 来处理 NGINX HTTP 请求的 Lua 函数；<br><br>  &ensp;&ensp;&ensp;&ensp;其他 ngx_ 和 lua_ 开头的函数，则分别属于 NGINX 和 Lua 的内置函数。</p>
</li>
</ul>
<h2 id="ngx-ctx"><a href="#ngx-ctx" class="headerlink" title="ngx.ctx"></a>ngx.ctx</h2><p>ngx.ctx 可以在同一个请求的不同阶段之间共享数据。它其实就是一个普通的 Lua 的 table，所以速度很快，还可以存储各种 Lua 的对象。它的生命周期是请求级别的，当一个请求结束的时候，ngx.ctx 也会跟着被销毁掉。</p>
<h2 id="定时任务"><a href="#定时任务" class="headerlink" title="定时任务"></a>定时任务</h2><p>ngx.timer.at，用来执行一次性的定时任务；<br>ngx.time.every，用来执行固定周期的定时任务。</p>
<h2 id="特权进程"><a href="#特权进程" class="headerlink" title="特权进程"></a>特权进程</h2><p>我们都知道 Nginx 主要分为 master 进程和 worker 进程，其中，真正处理用户请求的是 worker 进程。</p>
<p>而 OpenResty 在 Nginx 的基础上进行了扩展，增加了特权进程：privileged agent。</p>
<p>特权进程很特别：</p>
<ul>
<li>它不监听任何端口，这就意味着不会对外提供任何服务；</li>
<li>它拥有和 master 进程一样的权限，一般来说是 root 用户的权限，这就让它可以做很多 worker 进程不可能完成的任务；</li>
<li>特权进程只能在 init_by_lua 上下文中开启；</li>
<li>另外，特权进程只有运行在 init_worker_by_lua 上下文中才有意义，因为没有请求触发，也就不会走到content、access 等上下文去。</li>
</ul>
<p>开启特权进程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">init_by_lua_block &#123;</span><br><span class="line">    local process &#x3D; require &quot;ngx.process&quot;</span><br><span class="line"></span><br><span class="line">    local ok, err &#x3D; process.enable_privileged_agent()</span><br><span class="line">    if not ok then</span><br><span class="line">        ngx.log(ngx.ERR, &quot;enables privileged agent failed error:&quot;, err)</span><br><span class="line">    end</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nginx: master process</span><br><span class="line">nginx: worker process</span><br><span class="line">nginx: privileged agent process</span><br></pre></td></tr></table></figure>

<h2 id="test-nginx"><a href="#test-nginx" class="headerlink" title="test::nginx"></a>test::nginx</h2><p>test::nginx 是 OpenResty 测试体系中的核心，OpenResty 本身和周边的 lua-rety 库，都是使用它来组织和编写测试集的。</p>
<p>虽然它一个是测试框架，但它的门槛非常高。这是因为， test::nginx 和一般的测试框架不同，并非基于断言，也不使用 Lua 语言，这就要求开发者从零开始学习和使用 test::nginx，并得扭转自身对测试框架固有的认知。</p>
<p>test::nginx 糅合了 Perl、数据驱动以及 DSL（领域小语言）。对于同一份测试案例集，通过对参数和环境变量的控制，可以实现乱序执行、多次重复、内存泄漏检测、压力测试等不同的效果。</p>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》5.需要注意的点</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B5.%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E7%82%B9/</url>
    <content><![CDATA[<h1 id="需要注意的点"><a href="#需要注意的点" class="headerlink" title="需要注意的点"></a>需要注意的点</h1><h2 id="时间-API"><a href="#时间-API" class="headerlink" title="时间 API"></a>时间 API</h2><p>返回当前时间的 API，如果没有非阻塞网络 IO 操作来触发，便会一直返回缓存的值，而不是像我们想的那样，能够返回当前的实时时间。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ resty -e &#39;ngx.say(ngx.now())</span><br><span class="line">os.execute(&quot;sleep 1&quot;)</span><br><span class="line">ngx.say(ngx.now())&#39;</span><br></pre></td></tr></table></figure>

<p>在两次调用 ngx.now 之间，使用 Lua 的阻塞函数 sleep 了 1 秒钟，但从打印的结果来看，这两次返回的时间戳却是一模一样的。<br>如果换成是非阻塞的 sleep 函数，它就会打印出不同的时间戳了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ resty -e &#39;ngx.say(ngx.now())</span><br><span class="line">ngx.sleep(1)</span><br><span class="line">ngx.say(ngx.now())&#39;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="json-编码时无法区分-array-和-dict"><a href="#json-编码时无法区分-array-和-dict" class="headerlink" title="json 编码时无法区分 array 和 dict"></a>json 编码时无法区分 array 和 dict</h2><p>json 对空 table 编码的时候，无法确定编码为数组还是字典。</p>
<p>OpenResty 的 cjson 库，默认把空 table 当做字典来编码。我们可以通过 encode_empty_table_as_object 这个函数，来修改这个全局的默认值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">resty -e &#39;local cjson &#x3D; require &quot;cjson&quot;</span><br><span class="line">cjson.encode_empty_table_as_object(false)</span><br><span class="line">local t &#x3D; &#123;&#125;</span><br><span class="line">print(cjson.encode(t))&#39;</span><br></pre></td></tr></table></figure>

<p>全局这种设置的影响面比较大，可以指定某个 table 的编码规则：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">resty -e &#39;local cjson &#x3D; require &quot;cjson&quot;</span><br><span class="line">local t &#x3D; &#123;&#125;</span><br><span class="line">setmetatable(t, cjson.empty_array_mt)</span><br><span class="line">print(cjson.encode(t))</span><br><span class="line">t &#x3D; &#123;123&#125;</span><br><span class="line">print(cjson.encode(t))&#39;</span><br></pre></td></tr></table></figure>

<h2 id="真值和空值"><a href="#真值和空值" class="headerlink" title="真值和空值"></a>真值和空值</h2><h3 id="ngx-null"><a href="#ngx-null" class="headerlink" title="ngx.null"></a>ngx.null</h3><p>因为 Lua 的 nil 无法作为 table 的 value，所以 OpenResty 引入了 ngx.null，作为 table 中的空值。<br>只有 nil 和 false 是假值，ngx.null 的布尔值为真。如果遗漏了这一点，就很容易踩坑，比如在使用 lua-resty-redis 的时候，做了下面这个判断：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local res, err &#x3D; red:get(&quot;dog&quot;)</span><br><span class="line">if not res then</span><br><span class="line">    res &#x3D; res + &quot;test&quot;</span><br><span class="line">end </span><br></pre></td></tr></table></figure>

<p>在 dog 这个 key 不存在的情况下，这段代码就 500 崩溃了。</p>
<h3 id="cdata-NULL"><a href="#cdata-NULL" class="headerlink" title="cdata:NULL"></a>cdata:NULL</h3><p>当通过 LuaJIT FFI 接口去调用 C 函数，而这个函数返回一个 NULL 指针，那么就会遇到另外一种空值，即 cdata:NULL 。<br>和 ngx.null 一样，cdata:NULL 也是真值。但下面这段代码，会打印出 true，也就是说 cdata:NULL 是和 nil 相等的：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ resty -e &#39;local ffi &#x3D; require &quot;ffi&quot;</span><br><span class="line">local cdata_null &#x3D; ffi.new(&quot;void*&quot;, nil)</span><br><span class="line">ngx.say(cdata_null &#x3D;&#x3D; nil)&#39;</span><br></pre></td></tr></table></figure>

<h3 id="cjson-null"><a href="#cjson-null" class="headerlink" title="cjson.null"></a>cjson.null</h3><p>Lua 中的 nil，被 json encode 和 decode 一圈儿之后，就变成了 cjson.null。它引入的原因和 ngx.null 是一样的，因为 nil 无法在 table 中作为 value。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ resty -e &#39;local cjson &#x3D; require &quot;cjson&quot;</span><br><span class="line">local data &#x3D; cjson.encode(nil)</span><br><span class="line">local decode_null &#x3D; cjson.decode(data)</span><br><span class="line">ngx.say(decode_null &#x3D;&#x3D; cjson.null)&#39;</span><br></pre></td></tr></table></figure>

<h3 id="变量的个数限制"><a href="#变量的个数限制" class="headerlink" title="变量的个数限制"></a>变量的个数限制</h3><p>Lua 中，一个函数的局部变量的个数，和 upvalue 的个数都是有上限的，你可以从 Lua 的源码中得到印证：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;*</span><br><span class="line">@@ LUAI_MAXVARS is the maximum number of local variables per function</span><br><span class="line">@* (must be smaller than 250).</span><br><span class="line">*&#x2F;</span><br><span class="line">#define LUAI_MAXVARS 200</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;*</span><br><span class="line">@@ LUAI_MAXUPVALUES is the maximum number of upvalues per function</span><br><span class="line">@* (must be smaller than 250).</span><br><span class="line">*&#x2F;</span><br><span class="line">#define LUAI_MAXUPVALUES 60</span><br></pre></td></tr></table></figure>

<p>这两个阈值，分别被硬编码为 200 和 60。虽说你可以手动修改源码来调整这两个值，不过最大也只能设置为 250。</p>
<p>一般情况下，我们不会超过这个阈值，但写 OpenResty 代码的时候，还是要留意这个事情，不要过多地使用局部变量和 upvalue，而是要尽可能地使用 do .. end 做一层封装，来减少局部变量和 upvalue 的个数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local re_find &#x3D; ngx.re.find</span><br><span class="line">function foo()</span><br><span class="line">    ...</span><br><span class="line">end</span><br><span class="line">function bar()</span><br><span class="line">    ...</span><br><span class="line">end</span><br><span class="line">function fn()</span><br><span class="line">    ...</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>如果只有函数 foo 使用到了 re_find， 可以这样改造下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">do</span><br><span class="line">    local re_find &#x3D; ngx.re.find</span><br><span class="line">    function foo()</span><br><span class="line">        ...</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line">function bar()</span><br><span class="line">    ...</span><br><span class="line">end</span><br><span class="line">function fn()</span><br><span class="line">    ...</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>这样一来，在 main 函数的层面上，就少了 re_find 这个局部变量。这在单个的大的 Lua 文件中，算是一个优化技巧。</p>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》6.性能优化</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B6.%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h1><h2 id="避免使用-NYI"><a href="#避免使用-NYI" class="headerlink" title="避免使用 NYI"></a>避免使用 NYI</h2><h3 id="pairs-vs-ipairs"><a href="#pairs-vs-ipairs" class="headerlink" title="pairs() vs ipairs()"></a>pairs() vs ipairs()</h3><p>如果 table 内部为 array，应该优先使用哪个？为什么？</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/pairs%20vs%20ipairs.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">pairs vs ipairs</div>
</center>

<h3 id="NYI（Not-Yet-Implemented）的概念"><a href="#NYI（Not-Yet-Implemented）的概念" class="headerlink" title="NYI（Not Yet Implemented）的概念"></a>NYI（Not Yet Implemented）的概念</h3><p>LuaJIT 的运行时环境，除了一个汇编实现的 Lua 解释器外，还有一个可以直接生成机器代码的 JIT 编译器。</p>
<p>LuaJIT 中 JIT 编译器的实现还不完善，有一些原语它还无法编译，因为这些原语实现起来比较困难，再加上 LuaJIT 的作者目前处于半退休状态。</p>
<p>这些原语包括常见的 pairs() 函数、unpack() 函数、基于 Lua CFunction 实现的 Lua C 模块等。</p>
<p>这样一来，当 JIT 编译器在当前代码路径上遇到它不支持的操作时，便会退回到解释器模式。</p>
<p>全称为 Not Yet Implemented <a href="http://wiki.luajit.org/NYI">NYI 完整列表</a></p>
<span id="more"></span>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/NYI%20%E9%83%A8%E5%88%86%E7%A4%BA%E4%BE%8B.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">NYI 部分示例</div>
</center>

<br/>
string.byte 对应的能否被编译的状态是 yes，表明可以被 JIT。

<p>string.char 对应的编译状态是 2.1，表明从 LuaJIT 2.1 开始支持。</p>
<p>string.dump 对应的编译状态是 never，即不会被 JIT，会退回到解释器模式。</p>
<p>string.find 对应的编译状态是 2.1 partial，意思是从 LuaJIT 2.1 开始部分支持，后面的备注中写的是 只支持搜索固定的字符串，不支持模式匹配。所以对于固定字符串的查找，使用 string.find 是可以被 JIT 的。</p>
<h3 id="NYI-的替代方案"><a href="#NYI-的替代方案" class="headerlink" title="NYI 的替代方案"></a>NYI 的替代方案</h3><h4 id="string-gsub-函数"><a href="#string-gsub-函数" class="headerlink" title="string.gsub() 函数"></a>string.gsub() 函数</h4><p>这个函数是一个 NYI 原语，无法被 JIT 编译。<br>它是 Lua 内置的字符串操作函数，作用是做全局的字符串替换。</p>
<p>打开 <a href="https://github.com/openresty/lua-nginx-module#readme">lua-nginx-module 的 GitHub 文档页面</a>，可以用 gsub 作为关键字，在文档页面中搜索，找到 ngx.re.gsub</p>
<h4 id="string-find-函数"><a href="#string-find-函数" class="headerlink" title="string.find() 函数"></a>string.find() 函数</h4><p>和 string.gsub 不同的是，string.find 在 plain 模式（即固定字符串的查找）下，是可以被 JIT 的；<br>而带有正则这种的字符串查找，string.find 并不能被 JIT ，这时就要换用 OpenResty 自己的 API，也就是 ngx.re.find 来完成。</p>
<p>所以，当在 OpenResty 中做字符串查找时，首先一定要明确区分，要查找的是固定的字符串，还是正则表达式。</p>
<p>如果是前者，就要用 string.find，并且记得把最后的 plain 设置为 true：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">string.find(&quot;foo bar&quot;, &quot;foo&quot;, 1, true)</span><br></pre></td></tr></table></figure>

<p>如果是后者，应该用 OpenResty 自己的 API，并开启 PCRE 的 JIT 选项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ngx.re.find(&quot;foo bar&quot;, &quot;^foo&quot;, &quot;jo&quot;)</span><br></pre></td></tr></table></figure>

<p>可以做一层封装，并把优化选项默认打开，不要让最终的使用者知道这么多细节。这样，对外就是统一的字符串查找函数了。</p>
<h4 id="pairs-函数"><a href="#pairs-函数" class="headerlink" title="pairs() 函数"></a>pairs() 函数</h4><p>遍历哈希表的 pairs() 函数，它也不能被 JIT 编译。<br>这个并没有等价的替代方案，只能尽量避免使用，或者改用数字下标访问的数组，特别是在热代码路径上不要遍历哈希表。<br>代码热路径的意思是，这段代码会被反复执行很多次，比如在一个很大的循环里面。</p>
<h3 id="实践总结"><a href="#实践总结" class="headerlink" title="实践总结"></a>实践总结</h3><ol>
<li><p>优先使用 OpenResty 提供的 API，而不是 Lua 的标准库函数。这里要牢记， Lua 是嵌入式语言，我们实际上是在 OpenResty 中编程，而不是 Lua。</p>
</li>
<li><p>如果万不得已要使用 NYI 原语，请一定确保它没有在代码热路径上。</p>
</li>
</ol>
<h3 id="如何检测-NYI？"><a href="#如何检测-NYI？" class="headerlink" title="如何检测 NYI？"></a>如何检测 NYI？</h3><p>LuaJIT 自带的 jit.dump 和 jit.v 模块。它们都可以打印出 JIT 编译器工作的过程。<br>前者会输出非常详细的信息，可以用来调试 LuaJIT 本身；<br>后者的输出比较简单，每行对应一个 trace，通常用来检测是否可以被 JIT。</p>
<h4 id="想要简单验证的话，-使用-resty-就足够了"><a href="#想要简单验证的话，-使用-resty-就足够了" class="headerlink" title="想要简单验证的话， 使用 resty 就足够了"></a>想要简单验证的话， 使用 resty 就足够了</h4><p>其中，resty 的 -j 就是和 LuaJIT 相关的选项；后面的值为 dump 和 v，就对应着开启 jit.dump 和 jit.v 模式。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/resty%20-j.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">resty -j</div>
</center>

<br/>
在 jit.v 模块的输出中，每一行都是一个成功编译的 trace 对象。上面是一个能够被 JIT 的例子，而如果遇到 NYI 原语，输出里面就会指明 NYI，比如下面这个 pairs 的例子：

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/test_NYI.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">test_NYI</div>
</center>

<h4 id="系统验证"><a href="#系统验证" class="headerlink" title="系统验证"></a>系统验证</h4><p>可以先在 init_by_lua 中，添加以下两行代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local v &#x3D; require &quot;jit.v&quot;</span><br><span class="line">v.on(&quot;&#x2F;tmp&#x2F;jit.log&quot;)</span><br></pre></td></tr></table></figure>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/test%20jit%20code.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">test jit code</div>
</center>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/jit_log.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">jit_log</div>
</center>

<h2 id="避免使用阻塞操作"><a href="#避免使用阻塞操作" class="headerlink" title="避免使用阻塞操作"></a>避免使用阻塞操作</h2><p>OpenResty 之所以可以保持很高的性能，简单来说，是因为它借用了 Nginx 的事件处理和 Lua 的协程机制。</p>
<ul>
<li>在遇到网络 I/O 等需要等待返回才能继续的操作时，就会先调用 Lua 协程的 yield 把自己挂起，然后在 Nginx 中注册回调；</li>
<li>在 I/O 操作完成（也可能是超时或者出错）后，由 Nginx 回调 resume，来唤醒 Lua 协程。</li>
</ul>
<p>这样的流程，保证了 OpenResty 可以一直高效地使用 CPU 资源，来处理所有的请求。</p>
<p>在这个处理流程中，如果没有使用 cosocket 这种非阻塞的方式，而是用阻塞的函数来处理 I/O，那么 LuaJIT 就不会把控制权交给 Nginx 的事件循环。这就会导致，其他的请求要一直排队等待阻塞的事件处理完，才会得到响应。</p>
<p>另外，Lua 世界的库很可能会带来阻塞，让原本高性能的服务，直接下降几个数量级。在可选择的情况下，一般要选择 OpenResty 或者 LuaJit 实现的库，而不是采用 Lua 世界的库。</p>
<p>综上所述，在 OpenResty 的编程中，对于可能出现阻塞的函数调用，要特别谨慎；否则，一行阻塞的代码，就会把整个服务的性能拖垮，让服务性能下降 10 倍。</p>
<h3 id="os-execute"><a href="#os-execute" class="headerlink" title="os.execute"></a>os.execute</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">os.execute(&quot; cp test.exe &#x2F;tmp &quot;)</span><br><span class="line"></span><br><span class="line">os.execute(&quot; openssl genrsa -des3 -out private.pem 2048 &quot;)</span><br></pre></td></tr></table></figure>
<p>os.execute 是 Lua 的内置函数，属于阻塞操作，而在 Lua 世界中，也确实是用这种方式来调用外部命令的。</p>
<p>但是，我们要记住，Lua 是一种嵌入式语言，它在不同的上下文环境中，会有完全不同的推荐用法。</p>
<p>在 OpenResty 的环境中，os.execute 会阻塞当前请求。所以，如果这个命令的执行时间特别短，那么影响还不是很大；</p>
<p>可如果这个命令，需要执行几百毫秒甚至几秒钟的时间，那么性能就会有急剧的下降。</p>
<p>解决方案：</p>
<ol>
<li>可以优先使用 优先使用 FFI 的方式来调用</li>
<li>使用基于 ngx.pipe 的 lua-resty-shell 库</li>
</ol>
<h3 id="磁盘-I-O"><a href="#磁盘-I-O" class="headerlink" title="磁盘 I/O"></a>磁盘 I/O</h3><p>比如 io.open ，属于阻塞操作，来获取某个文件中的所有内容。</p>
<p>如果在 init 和 init worker 中调用，那么它其实是个一次性的动作，并没有影响任何终端用户的请求，是完全可以被接受的。</p>
<p>但是，如果每一个用户的请求，都会触发磁盘的读写，那就变得不可接受了。</p>
<p>解决方案：</p>
<ol>
<li>可以使用 lua-io-nginx-module 这个第三方的 C 模块。这种方式的原理是，lua-io-nginx-module 利用了 Nginx 的线程池，把磁盘 I/O 操作从主线程转移到另外一个线程中处理，这样，主线程就不会因为磁盘 I/O 操作而被阻塞。不过，使用这个库时，你需要重新编译 Nginx，因为它是一个 C 模块。</li>
<li>尝试架构上的调整。对于这类磁盘 I/O，是否可以换种方式，不再读写本地磁盘。比如记录日志 ngx.log 会大量而频繁的磁盘写入，也会严重地影响性能。这时可以把日志发送到远端的日志服务器上，这样就可以用 cosocket 来完成非阻塞的网络通信了，也就是把阻塞的磁盘 I/O 丢给日志服务，不要阻塞对外的服务。</li>
</ol>
<h3 id="luasocket"><a href="#luasocket" class="headerlink" title="luasocket"></a>luasocket</h3><p>也是容易被开发者用到的一个 Lua 内置库，属于阻塞操作，经常有人分不清 luasocket 和 OpenResty 提供的 cosocket。luasocket 也可以完成网络通信的功能，但它并没有非阻塞的优势。如果使用了 luasocket，那么性能也会急剧下降。</p>
<p>但是，luasocket 同样有它独特的使用场景。前面讲过，cosocket 在不少阶段是无法使用的，一般可以用 ngx.timer 的方式来绕过。同时，也可以在 init_by_lua* 和 init_worker_by_lua* 这种一次性的阶段中，使用 luasocket 来完成 cosocket 的功能。</p>
<h2 id="字符串拼接"><a href="#字符串拼接" class="headerlink" title="字符串拼接"></a>字符串拼接</h2><p>在 Lua 中，字符串是不可变的。涉及到字符串的新增和 GC 时，每当新增一个字符串，LuaJIT 都得调用 lj_str_new，去查询这个字符串是否已经存在；没有的话，便需要再创建新的字符串。如果操作很频繁，自然就会对性能有非常大的影响。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ resty -e &#39;local begin &#x3D; ngx.now()</span><br><span class="line">local s &#x3D; &quot;&quot;</span><br><span class="line">-- for 循环，使用 .. 进行字符串拼接</span><br><span class="line">for i &#x3D; 1, 100000 do</span><br><span class="line">    s &#x3D; s .. &quot;a&quot;</span><br><span class="line">end</span><br><span class="line">ngx.update_time()</span><br><span class="line">print(ngx.now() - begin)</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>
<p>改为使用 table.concat</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ resty -e &#39;local begin &#x3D; ngx.now()</span><br><span class="line">local t &#x3D; &#123;&#125;</span><br><span class="line">-- for 循环，使用数组来保存字符串，自己维护数组的长度</span><br><span class="line">for i &#x3D; 1, 100000 do</span><br><span class="line">    t[i] &#x3D; &quot;a&quot;</span><br><span class="line">end</span><br><span class="line">local s &#x3D;  table.concat(t, &quot;&quot;)</span><br><span class="line">ngx.update_time()</span><br><span class="line">print(ngx.now() - begin)</span><br><span class="line">&#39;</span><br></pre></td></tr></table></figure>

<h2 id="ngx-location-capture"><a href="#ngx-location-capture" class="headerlink" title="ngx.location.capture"></a>ngx.location.capture</h2><p>在 OpenResty 中如果使用子请求，会使用到 ngx.location.capture 这个函数，但是根据 <a href="https://github.com/openresty/lua-nginx-module#ngxlocationcapture">ngx.location.capture 的官方文档</a> 以及作者的亲自回复，如果在传递一个很大的 body 的时候，应该使用流式的 cosocket 库来代替。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/%E5%85%B3%E4%BA%8E%20ngx.location.capture%20%E7%9A%84%E6%9F%90%E6%AC%A1%E5%9B%9E%E5%A4%8D.png">
    <br>
</center>

<br/>
因为这个函数每次都会先把很大的 body 放到内存里，然后再处理转发，这样的效率是非常低的。

<h2 id="table-new-narray-nhash"><a href="#table-new-narray-nhash" class="headerlink" title="table.new(narray, nhash)"></a>table.new(narray, nhash)</h2><p>这个函数，会预先分配好指定的数组和哈希的空间大小，而不是在插入元素时自增长，这也是它的两个参数 narray 和 nhash 的含义。<br>如果不使用这个函数，自增长是一个代价比较高的操作，会涉及到空间分配、resize 和 rehash 等，我们应该尽量避免。</p>
<p>table.new 的文档并没有出现在 LuaJIT 的官网，而是深藏在 GitHub 项目的 <a href="https://github.com/openresty/luajit2/blob/v2.1-agentzh/doc/extensions.html">扩展文档</a> 里，用谷歌也很难找到，所以很多人并不知道这个函数的存在。</p>
<p>超出预设的空间大小，也可以正常使用，只不过性能会退化，也就失去了使用 table.new 的意义。</p>
<p>需要根据实际场景，来预设好 table.new 中数组和哈希空间的大小，这样才能在性能和内存占用上找到一个平衡点。</p>
<p>下图是在 lua-resty-mysql 中的使用方法，同样，在 lua-resty-redis 以及其它项目里也存在类似的例子</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/table.new%20%E4%BD%BF%E7%94%A8%E4%BE%8B%E5%AD%90.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">table.new 使用例子</div>
</center>

<h2 id="table-clear"><a href="#table-clear" class="headerlink" title="table.clear()"></a>table.clear()</h2><p>清空 table，它用来清空某个 table 里的所有数据，但并不会释放数组和哈希部分占用的内存。<br>所以，它在循环利用 Lua table 时非常有用，可以避免反复创建和销毁 table 的开销。</p>
<p>对于大的 table，效率反而会降低，因为清空的时间高于重新创建的时间 （&gt;1000）</p>
<h2 id="table-insert"><a href="#table-insert" class="headerlink" title="table.insert"></a>table.insert</h2><p>table.insert 虽然是一个很常见的操作，但性能并不乐观。<br>如果不是根据指定下标来插入元素，那么每次都需要调用 LuaJIT 的 lj_tab_len 来获取数组的长度，以便插入队尾。获取 table 长度的时间复杂度为 O(n) 。</p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/%E6%89%8B%E5%8A%A8%E8%AE%A1%E7%AE%97%E4%B8%8B%E6%A0%87%E9%81%BF%E5%85%8D%20table.insert.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">手动计算下标避免 table.insert</div>
</center>

<br/>
一个综合实际优化的例子：<br/>
　　　　ingress-nginx 是 k8s 官方的一个项目，主要使用 Go、 Nginx 和 lua-nginx-module 来处理入口流量。<br/>
　　　　其中一个关于使用 table 相关函数进行性能优化的 PR：<br/>
　　　　　　　　https://github.com/kubernetes/ingress-nginx/pull/3673/commits

<h2 id="OpenResty-的-table-扩展函数"><a href="#OpenResty-的-table-扩展函数" class="headerlink" title="OpenResty 的 table 扩展函数"></a>OpenResty 的 table 扩展函数</h2><p>OpenResty 自己维护的 LuaJIT 分支，也对 table 做了扩展，它 <a href="https://github.com/openresty/luajit2/#new-api">新增了几个 API：table.isempty、table.isarray、 table.nkeys 和 table.clone</a>。</p>
<h2 id="关于-OpenResty-的正则"><a href="#关于-OpenResty-的正则" class="headerlink" title="关于 OpenResty 的正则"></a>关于 OpenResty 的正则</h2><p>OpenResty 中并行着两套字符串匹配方法：Lua 自带的 sting 库，以及 OpenResty 提供的 ngx.re.* API。<br>其中， Lua 正则模式匹配是自己独有的格式，和 PCRE 的写法不同。</p>
<p>Lua 自带的正则匹配库，不仅代码维护成本高，而且性能低—，不能被 JIT，而且被编译过一次的模式也不会被缓存。</p>
<p>所以，在使用 Lua 内置的 string 库去做 find、match 等操作时，如果有类似正则这样的需求，直接使用 OpenResty 提供的 ngx.re 来替代。</p>
<p>只有在查找固定字符串的时候，我们才考虑使用 plain 模式来调用 string 库。</p>
<p>这是一个函数示例：<a href="https://github.com/openresty/lua-nginx-module#ngxrematch">ngx.re.match</a></p>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    data-src="https://yxd-blog.oss-cn-shanghai.aliyuncs.com/OpenResty/OpenResty%20%E6%AD%A3%E5%88%99%E9%80%89%E9%A1%B9.png">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">OpenResty 正则选项</div>
</center>

<br/>
通过查看参数 options 的文档，会发现，只要我们把它设置为 jo，就开启了 PCRE 的 JIT。
这样，使用 ngx.re.gsub 的代码，既可以被 LuaJIT 进行 JIT 编译，也可以被 PCRE JIT 进行 JIT 编译。

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local function fun1(str)</span><br><span class="line">    local aaaa, bbbb, ccccc &#x3D; ngx.re.find(str, &quot;\\?|&amp;&quot;, &quot;jo&quot;)</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">local function fun2(str)</span><br><span class="line">    local aaaa, bbbb, ccccc &#x3D; ngx.re.find(str, &quot;\\?|&amp;&quot;)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p>性能差距在一个数量级，大概 20 倍左右。</p>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
  <entry>
    <title>《OpenResty精华整理》7.一些比较有用的库</title>
    <url>/%E3%80%8AOpenResty%E7%B2%BE%E5%8D%8E%E6%95%B4%E7%90%86%E3%80%8B7.%E4%B8%80%E4%BA%9B%E6%AF%94%E8%BE%83%E6%9C%89%E7%94%A8%E7%9A%84%E5%BA%93/</url>
    <content><![CDATA[<h1 id="一些比较有用的库"><a href="#一些比较有用的库" class="headerlink" title="一些比较有用的库"></a>一些比较有用的库</h1><h2 id="awesome-resty"><a href="#awesome-resty" class="headerlink" title="awesome-resty"></a>awesome-resty</h2><p><a href="https://github.com/bungle/awesome-resty">awesome-resty</a> 这个项目，维护了几乎所有 OpenResty 可用的包。</p>
<h2 id="lua-resty-jit-uuid"><a href="#lua-resty-jit-uuid" class="headerlink" title="lua-resty-jit-uuid"></a>lua-resty-jit-uuid</h2><p><a href="https://github.com/thibaultCha/lua-resty-jit-uuid">lua-resty-jit-uuid</a> 用于生成 uuid，注意如果在容器中使用需要对种子特殊处理。</p>
<h2 id="lua-rapidjson"><a href="#lua-rapidjson" class="headerlink" title="lua-rapidjson"></a>lua-rapidjson</h2><p><a href="https://github.com/xpol/lua-rapidjson">lua-rapidjson</a>，它是对 rapidjson 这个腾讯开源的 JSON 库的封装，以性能见长。支持 JSON Schema，JSON Schema 是一个通用的标准，借助这个标准，可以精确地描述接口中参数的格式，以及如何校验的问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;stringArray&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: &quot;array&quot;,</span><br><span class="line">    &quot;items&quot;: &#123; &quot;type&quot;: &quot;string&quot; &#125;,</span><br><span class="line">    &quot;minItems&quot;: 1,</span><br><span class="line">    &quot;uniqueItems&quot;: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h2 id="lua-resty-worker-events"><a href="#lua-resty-worker-events" class="headerlink" title="lua-resty-worker-events"></a>lua-resty-worker-events</h2><p><a href="https://github.com/Kong/lua-resty-worker-events">lua-resty-worker-events</a>，可以实现 OpenResty 中 worker 间通信。</p>
<p>比如有一个场景，存在多个 worker，只有一个 worker 收到了更新操作，并把结果写入了共享字典和自己 worker 内的 lru 缓存。那么，其他的 worker 怎么才能被通知去更新这项配置？这个时候这个库就派上用场了。</p>
<h2 id="lua-resty-limit-traffic"><a href="#lua-resty-limit-traffic" class="headerlink" title="lua-resty-limit-traffic"></a>lua-resty-limit-traffic</h2><p>常用的流量控制算法，有漏桶和令牌桶。</p>
<p><a href="https://github.com/openresty/lua-resty-limit-traffic">lua-resty-limit-traffic</a>，里面包含了 limit-req（限制请求速率）、 limit-count（限制请求数） 和 limit-conn （限制并发连接数）这三种不同的限制方式；并且提供了limit.traffic ，可以把这三种方式进行聚合使用。</p>
<h3 id="Nginx-的限速模块"><a href="#Nginx-的限速模块" class="headerlink" title="Nginx 的限速模块"></a>Nginx 的限速模块</h3><p>在 Nginx 中，limit_req 模块是最常用的限速模块，下面是一个简单的配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">limit_req_zone $binary_remote_addr zone&#x3D;one:10m rate&#x3D;1r&#x2F;s;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    location &#x2F;search&#x2F; &#123;</span><br><span class="line">        limit_req zone&#x3D;one burst&#x3D;5;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段代码是把终端的 IP 地址作为 key，申请了一块名为 one 的 10M 的内存空间地址，并把速率限制为每秒 1 个请求。</p>
<p>在 server 的 location 中，还引用了 one 这个限速规则，并把 brust 设置为 5。</p>
<p>这就表示在超过速率 1r/s 的情况下，同时允许有 5 个请求排队等待被处理，给出了一定的缓存区。</p>
<p>要注意，如果没有设置 brust ，超过速率的请求是会被直接拒绝的。Nginx 的这个模块基于漏桶来实现，resty.limit.req ，本质都是一样的。</p>
<ul>
<li>第一个问题是，限速的 key 被限制在 Nginx 的变量范围内，不能灵活地设置。比如，根据不同的省份和不同的客户端渠道，来设置不同的限速阈值，这种常见的需求用 Nginx 就没有办法实现。</li>
<li>另外一个更大的问题是，不能动态地调整速率，每次修改都需要重载 Nginx 服务。这样一来，根据不同的时间段限速这种需求，很难优雅的实现。</li>
</ul>
<h3 id="限速器的组合"><a href="#限速器的组合" class="headerlink" title="限速器的组合"></a>限速器的组合</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local lim1, err &#x3D; limit_req.new(&quot;my_req_store&quot;, 300, 200)</span><br><span class="line">local lim2, err &#x3D; limit_req.new(&quot;my_req_store&quot;, 200, 100)</span><br><span class="line">local lim3, err &#x3D; limit_conn.new(&quot;my_conn_store&quot;, 1000, 1000, 0.5)</span><br><span class="line"></span><br><span class="line">local limiters &#x3D; &#123;lim1, lim2, lim3&#125;</span><br><span class="line">local host &#x3D; ngx.var.host</span><br><span class="line">local client &#x3D; ngx.var.binary_remote_addr</span><br><span class="line">local keys &#x3D; &#123;host, client, client&#125;</span><br><span class="line"></span><br><span class="line">local delay, err &#x3D; limit_traffic.combine(limiters, keys, states)</span><br></pre></td></tr></table></figure>

<p>存在对 limiter 做演习的概念，第一个通过，被第二个拒绝，第一个不会被算做次数。<br>这样组合以后，就可以为多个限流器设置不同的阈值和 key，实现更复杂的业务需求。</p>
]]></content>
      <categories>
        <category>OpenResty</category>
      </categories>
      <tags>
        <tag>OpenResty</tag>
        <tag>OpenResty精华整理</tag>
      </tags>
  </entry>
</search>
